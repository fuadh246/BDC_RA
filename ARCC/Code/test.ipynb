{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html5lib\n",
    "import requests\n",
    "from openpyxl import Workbook\n",
    "from datetime import datetime\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_trim(content, content_type):\n",
    "    if content_type == 'HTML':\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    else:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    for tag in soup.recursiveChildGenerator():\n",
    "        try:\n",
    "            tag.attrs = None\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    for linebreak in soup.find_all('br'):\n",
    "        linebreak.extract()\n",
    "    for linebreak in soup.find_all('hr'):\n",
    "        linebreak.extract()\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_spaces(string):\n",
    "    pattern = r'\\s+'\n",
    "    replaced_string = re.sub(pattern, ' ', string)\n",
    "    return replaced_string\n",
    "\n",
    "\n",
    "def find_qrt_date(content):\n",
    "    qtr_date = content.find_all(text=re.compile(\n",
    "        r'for\\s+(the\\s+)?(fiscal\\s+)?year\\s+ended\\s+|for\\s+the\\s+quarter\\s+ended\\s+|for\\s+the\\s+quarterly\\s+period\\s+ended\\s+', re.IGNORECASE))\n",
    "    qtr_match = re.search(\n",
    "        r'([A-Za-z]+)\\s+(\\d{1,2}),\\s+(\\d{4})', qtr_date[0].replace('\\n', ''))\n",
    "    if qtr_match is None:\n",
    "        qtr_match = qtr_match = re.search(\n",
    "            r'([A-Za-z]+) (\\d{1,2}), (\\d{4})', qtr_date[1])\n",
    "    return remove_multiple_spaces(str(qtr_match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "qtr_date = 'March 31, 2019'\n",
    "date = qtr_date\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    print(type(all_tags))\n",
    "    count = 0\n",
    "    date_str = None\n",
    "    for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "        date_str = re.search(regex_pattern, next_line_text)\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "            date_str = re.search(regex_pattern, next_line_text)\n",
    "            print(date_str)\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(\n",
    "                regex_pattern, next_line)\n",
    "            print(date_str)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            print(qtr_date)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                print(qtr_date.replace(',', '').strip().lower(),\n",
    "                      date_str.replace(',', '').strip().lower())\n",
    "                count += 1\n",
    "                print('Table found: ')\n",
    "                print('Table #', count)\n",
    "                html_table = tag.find_next('table')\n",
    "                if master_table is None:\n",
    "                    master_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    master_table = master_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan,\n",
    "                                                                                              regex=True)\n",
    "                    master_table = master_table.dropna(how='all', axis=0)\n",
    "                else:\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan,\n",
    "                                                                                        regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "                    master_table = master_table.append(\n",
    "                        new_table.dropna(how='all', axis=0).reset_index(\n",
    "                            drop=True).drop(index=0),\n",
    "                        ignore_index=True)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    print(tag)\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "    # print(next_line_text)\n",
    "    date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = content.find_all(True)\n",
    "all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    next_line_text = tag.next.text.strip()\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_str = re.search(regex_pattern, next_line_text)\n",
    "    if date_str is None:\n",
    "        next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "        date_str = re.search(regex_pattern, next_line_text)\n",
    "        print(date_str)\n",
    "    if date_str is None:\n",
    "        next_line = tag.next.text.strip()\n",
    "        date_str = re.search(\n",
    "            regex_pattern, next_line)\n",
    "        print(date_str)\n",
    "    if date_str is not None:\n",
    "        date_str = str(date_str.group(1))\n",
    "        date_str = unicodedata.normalize('NFKD', date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = extract_tables(content, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qtr_date = date\n",
    "# for tag in content.find_all(text=re.compile('^.*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS.*$')):\n",
    "#     next_line_text = tag.next.text.strip()\n",
    "#     regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "#     date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "#     print(date_str)\n",
    "#     if date_str is None:\n",
    "#         next_line = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "#         date_str = re.search(regex_pattern, next_line)\n",
    "#     if date_str is None:\n",
    "#         next_line = tag.next.text.strip()\n",
    "#         date_str = re.search(\n",
    "#             regex_pattern, next_line).group(1)\n",
    "#     if date_str is not None:\n",
    "#         date_str = str(date_str)\n",
    "#         date_str = unicodedata.normalize('NFKD', date_str)\n",
    "#         print(date_str)\n",
    "#         print(qtr_date, date_str)\n",
    "#         print(type(qtr_date))\n",
    "#         if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "#             print(qtr_date, date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table(soi_table_df, append_str):\n",
    "    soi_table_df = soi_table_df.replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=1)\n",
    "    soi_table_df = soi_table_df.dropna(\n",
    "        how='all', axis=0).reset_index(drop=True)\n",
    "    print('1: ' + str(soi_table_df.shape))\n",
    "\n",
    "    # Separate header and data\n",
    "    soi_table_header = soi_table_df.iloc[0].dropna(how='any')\n",
    "    print('header: ')\n",
    "    print(soi_table_header)\n",
    "    soi_table_data_df = soi_table_df.rename(\n",
    "        columns=soi_table_df.iloc[0]).drop(soi_table_df.index[0])\n",
    "    print('2: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # Drop rows with only two non-null values\n",
    "    soi_table_data_df = soi_table_data_df.dropna(thresh=3)\n",
    "    print('4: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    columns_to_fill = ['Amortized Cost', 'Fair Value']\n",
    "    for col in columns_to_fill:\n",
    "        original_column_names = soi_table_data_df.columns.tolist()\n",
    "        soi_table_data_df.columns = soi_table_data_df.columns.str.replace(\n",
    "            ' ', '')\n",
    "        col_index = soi_table_data_df.columns.get_loc(col.replace(' ', ''))\n",
    "        soi_table_data_df.columns = original_column_names\n",
    "        next_col_index = col_index + 1\n",
    "        for i in range(len(soi_table_data_df)):\n",
    "            current_value = soi_table_data_df.iat[i, col_index]\n",
    "            if pd.isna(current_value) and next_col_index < len(soi_table_data_df.columns):\n",
    "                next_valid_index = next((j for j, v in enumerate(\n",
    "                    soi_table_data_df.iloc[i, next_col_index:], start=next_col_index) if pd.notna(v)), None)\n",
    "\n",
    "                if next_valid_index is not None:\n",
    "                    next_value = soi_table_data_df.iat[i, next_valid_index]\n",
    "                    soi_table_data_df.iat[i, col_index] = next_value\n",
    "                    soi_table_data_df.iat[i, next_valid_index] = pd.NA\n",
    "\n",
    "    # # Drop rows labeled as subtotals\n",
    "    # subtotal_rows = soi_table_data_df[soi_table_data_df['Company (1)'].str.contains(\n",
    "    #     'subtotal', case=False, na=False)]\n",
    "    # soi_table_data_df = soi_table_data_df[~soi_table_data_df.index.isin(\n",
    "    #     subtotal_rows.index)]\n",
    "    # print('3: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # # Drop rows based on regex pattern (e.g., 'subtotal' or 'total')\n",
    "    # pattern = r'^([Ss]ubtotal)|([Tt]otal)'\n",
    "    # mask = soi_table_data_df.apply(lambda row: row.astype(\n",
    "    #     str).str.contains(pattern, case=False, na=False)).any(axis=1)\n",
    "    # soi_table_data_df = soi_table_data_df[~mask]\n",
    "    # print('4: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # # Drop rows with all missing values\n",
    "    # soi_table_df = soi_table_df.dropna(how='all')\n",
    "    # print('5: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # # # Drop columns with all missing values\n",
    "    # soi_table_data_df = soi_table_data_df.dropna(how='all', axis=1)\n",
    "    # print('6: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # # Forward fill the first two columns\n",
    "    # col_indices = [0, 1]\n",
    "    # soi_table_data_df.iloc[:, col_indices] = soi_table_data_df.iloc[:, col_indices].fillna(\n",
    "    #     method='ffill')\n",
    "    # print('7: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # num_cols = soi_table_data_df.shape[1]\n",
    "    # for col_index in range(num_cols-3, num_cols):\n",
    "    #     col_name = soi_table_data_df.columns[col_index]\n",
    "    #     soi_table_data_df[col_name] = pd.to_numeric(\n",
    "    #         soi_table_data_df[col_name], errors='coerce').fillna(0)\n",
    "\n",
    "    # soi_table_data_df = soi_table_data_df.replace('-', 0, regex=False)\n",
    "    # print('8: ' + str(soi_table_data_df.shape))\n",
    "    soi_table_data_df = soi_table_data_df.reset_index(drop=True)\n",
    "\n",
    "    return soi_table_data_df\n",
    "\n",
    "\n",
    "process_table_ = process_table(master_table, \"hi\")\n",
    "process_table_.to_excel(\"ex.xlsx\")\n",
    "process_table_.to_csv('ex.csv')\n",
    "process_table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill the first two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/fuadhassan/Desktop/BDC_RA/ARCC/ARCC_Investment.xlsx'\n",
    "xls = pd.ExcelFile(path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "# Print the sheet names\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "# Read each sheet and store in the dictionary\n",
    "for sheet_name in sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name)\n",
    "    dfs[sheet_name] = df\n",
    "\n",
    "# Access and print individual DataFrames\n",
    "for sheet_name, df in dfs.items():\n",
    "    print(f\"Sheet Name: {sheet_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = content.find_all(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    next_line_text = tag.next.text.strip()\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_str = re.search(regex_pattern, next_line_text)\n",
    "    if date_str is None:\n",
    "        next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "        date_str = re.search(regex_pattern, next_line_text)\n",
    "        print(date_str)\n",
    "    if date_str is None:\n",
    "        next_line = tag.next.text.strip()\n",
    "        date_str = re.search(\n",
    "            regex_pattern, next_line)\n",
    "        print(date_str)\n",
    "    if date_str is not None:\n",
    "        date_str = str(date_str.group(1))\n",
    "        date_str = unicodedata.normalize('NFKD', date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "    date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "    date_str = unicodedata.normalize('NFKD', date_str)\n",
    "    if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "        html_table = tag.find_next('table')\n",
    "        while html_table and html_table.find_next_sibling() != None:\n",
    "            new_table = pd.read_html(\n",
    "                html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "            new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "            new_table = new_table.replace(\n",
    "                r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "            new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "            if master_table is None:\n",
    "                master_table = new_table\n",
    "            else:\n",
    "                master_table = pd.concat(\n",
    "                    [master_table, new_table], ignore_index=True)\n",
    "            html_table = html_table.find_next('table')\n",
    "master_table = master_table.applymap(\n",
    "    lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "    r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "    date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "    date_str = unicodedata.normalize('NFKD', date_str)\n",
    "    if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "        html_table = tag.find_next('table')\n",
    "        while html_table:\n",
    "            if html_table.find_next(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "                print(html_table.find_next(text=re.compile(\n",
    "                    '^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')))\n",
    "                break\n",
    "            html_table = html_table.find_next('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in content.find_all(text=re.compile(r'\\s+Pledged\\s', re.IGNORECASE)):\n",
    "    # Process the tag that matches the pattern\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content.txt', 'w') as file:\n",
    "    file.write(str(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "    for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "        regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "        next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "        date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "        date_str = unicodedata.normalize('NFKD', date_str)\n",
    "        if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "            html_table = tag.find_next('table')\n",
    "            while html_table:\n",
    "                if html_table.find_next(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "                    break\n",
    "                new_table = pd.read_html(\n",
    "                    html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                    'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                new_table = new_table.replace(\n",
    "                    r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                if master_table is None:\n",
    "                    master_table = new_table\n",
    "                else:\n",
    "                    master_table = pd.concat(\n",
    "                        [master_table, new_table], ignore_index=True)\n",
    "                html_table = html_table.find_next('table')\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "    for tag in soup_content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "        date_str = re.search(regex_pattern, next_line_text)\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "            date_str = re.search(regex_pattern, next_line_text)\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(\n",
    "                regex_pattern, next_line)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                # print('Table #', count)\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table and html_table.find_next(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "                    next_schedule_tag = html_table.find_next(text=re.compile(\n",
    "                        '^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$'))\n",
    "                    if not next_schedule_tag:\n",
    "                        break\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_table_ = process_table(master_table, \"\")\n",
    "process_table_.to_excel(\"example.xlsx\")\n",
    "process_table_.to_csv('example.csv')\n",
    "process_table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "for tag in content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "    regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "    date_str = re.search(regex_pattern, next_line_text).group(1)\n",
    "    date_str = unicodedata.normalize('NFKD', date_str)\n",
    "    if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "        html_table = tag.find_next('table')\n",
    "        while html_table and html_table.find_next(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "            html_table = html_table.find_next('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "    for tag in soup_content.find_all(text=re.compile('^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "        date_str = re.search(regex_pattern, next_line_text)\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(text=re.compile(regex_pattern)).text\n",
    "            date_str = re.search(regex_pattern, next_line_text)\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(\n",
    "                regex_pattern, next_line)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                html_table = tag.find_next('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(soup_content, qtr_date):\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "\n",
    "    for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(\n",
    "                text=re.compile(date_regex_pattern)).text\n",
    "            date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table and html_table.find_next(text=consolidated_schedule_regex):\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "qtr_date = 'March 31, 2019'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746911001575/a2202281z10-k.htm'\n",
    "# qtr_date = 'December 31, 2010'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "# def extract_tables(soup_content, qtr_date):\n",
    "#     consolidated_schedule_regex = re.compile(\n",
    "#         r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "#     date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "#     master_table = None\n",
    "#     all_tags = soup_content.find_all(True)\n",
    "#     count = 0\n",
    "\n",
    "#     for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "#         next_line_text = tag.next.text.strip()\n",
    "#         date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "#         if date_str is None:\n",
    "#             next_line_text = tag.find_next(\n",
    "#                 text=re.compile(date_regex_pattern)).text\n",
    "#             date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "#         if date_str is None:\n",
    "#             next_line = tag.next.text.strip()\n",
    "#             date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "#         if date_str is not None:\n",
    "#             date_str = str(date_str.group(1))\n",
    "#             date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "#             if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "#                 count += 1\n",
    "#                 html_table = tag.find_next('table')\n",
    "#                 while html_table and html_table.find_next(text=consolidated_schedule_regex):\n",
    "#                     new_table = pd.read_html(\n",
    "#                         html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "#                     new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "#                         'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "#                     new_table = new_table.replace(\n",
    "#                         r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "#                     new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "#                     if master_table is None:\n",
    "#                         master_table = new_table\n",
    "#                     else:\n",
    "#                         master_table = pd.concat(\n",
    "#                             [master_table, new_table], ignore_index=True)\n",
    "\n",
    "#                     html_table = html_table.find_next('table')\n",
    "\n",
    "#     master_table = master_table.applymap(\n",
    "#         lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "#     master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "#         r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "#     return master_table\n",
    "\n",
    "\n",
    "# master_table = extract_tables(content, qtr_date)\n",
    "# master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "# qtr_date = 'March 31, 2019'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746911001575/a2202281z10-k.htm'\n",
    "# qtr_date = 'December 31, 2010'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465910055721/a10-17362_110q.htm'\n",
    "qtr_date = 'September 30, 2010'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "\n",
    "    for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(\n",
    "                text=re.compile(date_regex_pattern)).text\n",
    "            date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table:\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                    # print(master_table)\n",
    "                    if html_table.find_next(text=consolidated_schedule_regex):\n",
    "                        next_line_text = tag.find_next(\n",
    "                            text=re.compile(date_regex_pattern)).text\n",
    "                        date_str2 = re.search(\n",
    "                            date_regex_pattern, next_line_text)\n",
    "                        print(date_str)\n",
    "                        print(date_str2.group(1))\n",
    "                        if date_str2.group(1) == date_str:\n",
    "                            break\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "qtr_date = 'March 31, 2019'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746911001575/a2202281z10-k.htm'\n",
    "qtr_date = 'December 31, 2010'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465910055721/a10-17362_110q.htm'\n",
    "# qtr_date = 'September 30, 2010'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000015/arccq1-1810q.htm'\n",
    "# qtr_date = 'March 31, 2018'\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "\n",
    "    for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(\n",
    "                text=re.compile(date_regex_pattern)).text\n",
    "            date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table and html_table.find_next(text=consolidated_schedule_regex):\n",
    "                    print('table found')\n",
    "                    # if html_table.find_next(text=consolidated_schedule_regex):\n",
    "                    #     print('next text found')\n",
    "                    next_line_text = tag.find_next(\n",
    "                        text=re.compile(date_regex_pattern)).text\n",
    "                    date_str2 = re.search(\n",
    "                        date_regex_pattern, next_line_text)\n",
    "                    print(date_str2.group(1), date_str)\n",
    "                    print(date_str2.group(1) is not date_str)\n",
    "                    if date_str2.group(1) is not date_str:\n",
    "                        print(\"broke here\")\n",
    "                        break\n",
    "                    print(\"moved to next table\")\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    # master_table = master_table.applymap(\n",
    "    #     lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    # master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "    #     r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    # return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "qtr_date = 'March 31, 2019'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746911001575/a2202281z10-k.htm'\n",
    "# qtr_date = 'December 31, 2010'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465910055721/a10-17362_110q.htm'\n",
    "# qtr_date = 'September 30, 2010'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000015/arccq1-1810q.htm'\n",
    "# qtr_date = 'March 31, 2018'\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "\n",
    "    for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(\n",
    "                text=re.compile(date_regex_pattern)).text\n",
    "            date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table and check_break_point(content):\n",
    "                    print('table found')\n",
    "                    # # if html_table.find_next(text=consolidated_schedule_regex):\n",
    "                    # #     print('next text found')\n",
    "                    # next_line_text = tag.find_next(\n",
    "                    #     text=re.compile(date_regex_pattern)).text\n",
    "                    # date_str2 = re.search(\n",
    "                    #     date_regex_pattern, next_line_text)\n",
    "                    # print(date_str2.group(1), date_str)\n",
    "                    # print(date_str2.group(1) is not date_str)\n",
    "                    # if date_str2.group(1) is not date_str:\n",
    "                    #     print(\"broke here\")\n",
    "                    #     break\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "                    print(\"moved to next table\")\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, qtr_date)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_break_point(content):\n",
    "    next_sibling = content.find_next_sibling()\n",
    "    if next_sibling and \"Derivative Instruments\" in next_sibling.text:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_in_larger_text(larger_text, target_text):\n",
    "    pattern = re.escape(target_text)\n",
    "    match = re.search(pattern, larger_text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company(1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interest(6)(12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acquisition  Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amortized  Cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair  Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percentage  of Net  Assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Funds and Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIC Flex, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership units (0.94 units)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/7/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covestia Capital Partners, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership interest (47.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/17/2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1862</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCI Equity, LLC(8)(9)(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Member interest (100.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/1/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Computers and Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Everspin Technologies, Inc.(25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designer and manufacturer of computer memory s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First lien senior secured loan ($8,000 par due...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.75% (Libor + 7.75%/M)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840</td>\n",
       "      <td>(5)(21)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warrant to purchase up to 480,000 shares of Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>(5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0   1   \\\n",
       "0                           Company(1) NaN   \n",
       "1        Investment Funds and Vehicles NaN   \n",
       "2                     CIC Flex, LP(10) NaN   \n",
       "3    Covestia Capital Partners, LP(10) NaN   \n",
       "4            HCI Equity, LLC(8)(9)(10) NaN   \n",
       "..                                 ...  ..   \n",
       "642                                NaN NaN   \n",
       "643          Computers and Electronics NaN   \n",
       "644    Everspin Technologies, Inc.(25) NaN   \n",
       "645                                NaN NaN   \n",
       "646                                NaN NaN   \n",
       "\n",
       "                                                    2   3   \\\n",
       "0                                 Business Description NaN   \n",
       "1                                                  NaN NaN   \n",
       "2                               Investment partnership NaN   \n",
       "3                               Investment partnership NaN   \n",
       "4                                   Investment company NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  Designer and manufacturer of computer memory s... NaN   \n",
       "645                                                NaN NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                                                    4   5   \\\n",
       "0                                           Investment NaN   \n",
       "1                                                  NaN NaN   \n",
       "2               Limited partnership units (0.94 units) NaN   \n",
       "3       Limited partnership interest (47.00% interest) NaN   \n",
       "4                   Member interest (100.00% interest) NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  First lien senior secured loan ($8,000 par due... NaN   \n",
       "645  Warrant to purchase up to 480,000 shares of Se... NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                          6   7                  8          9   \\\n",
       "0            Interest(6)(12) NaN  Acquisition  Date        NaN   \n",
       "1                        NaN NaN                NaN        NaN   \n",
       "2                        NaN NaN                NaN   9/7/2007   \n",
       "3                        NaN NaN                NaN  6/17/2008   \n",
       "4                        NaN NaN                NaN   4/1/2010   \n",
       "..                       ...  ..                ...        ...   \n",
       "642                      NaN NaN                NaN        NaN   \n",
       "643                      NaN NaN                NaN        NaN   \n",
       "644  8.75% (Libor + 7.75%/M) NaN                NaN   6/5/2015   \n",
       "645                      NaN NaN                NaN   6/5/2015   \n",
       "646                      NaN NaN                NaN        NaN   \n",
       "\n",
       "                  10  11           12  13                          14     15  \\\n",
       "0    Amortized  Cost NaN  Fair  Value NaN  Percentage  of Net  Assets    NaN   \n",
       "1                NaN NaN          NaN NaN                         NaN    NaN   \n",
       "2                NaN NaN            - NaN                         NaN    263   \n",
       "3                NaN NaN          487 NaN                         NaN   1862   \n",
       "4                NaN NaN            - NaN                         NaN    127   \n",
       "..               ...  ..          ...  ..                         ...    ...   \n",
       "642              NaN NaN        10659 NaN                         NaN  13534   \n",
       "643              NaN NaN          NaN NaN                         NaN    NaN   \n",
       "644              NaN NaN         7533 NaN                         NaN   7840   \n",
       "645              NaN NaN          355 NaN                         NaN    355   \n",
       "646              NaN NaN         7888 NaN                         NaN   8195   \n",
       "\n",
       "          16  17    18   19  \n",
       "0        NaN NaN   NaN  NaN  \n",
       "1        NaN NaN   NaN  NaN  \n",
       "2        (2) NaN   NaN  NaN  \n",
       "3        (2) NaN   NaN  NaN  \n",
       "4        NaN NaN   NaN  NaN  \n",
       "..       ...  ..   ...  ...  \n",
       "642      NaN NaN  0.26    %  \n",
       "643      NaN NaN   NaN  NaN  \n",
       "644  (5)(21) NaN   NaN  NaN  \n",
       "645      (5) NaN   NaN  NaN  \n",
       "646      NaN NaN   NaN  NaN  \n",
       "\n",
       "[647 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775023000036/arcc-20230630.htm'\n",
    "# date = 'June 30, 2023'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "# date = 'March 31, 2019'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746914001349/a2218339z10-k.htm'\n",
    "date = 'December 31, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000015/arccq1-1810q.htm'\n",
    "# date = 'March 31, 2018'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465913080832/a13-19678_110q.htm'\n",
    "# date = 'September 30, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000007/arccq4-1710k.htm'\n",
    "# date = 'December 31, 2017'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746915001240/a2222984z10-k.htm'\n",
    "date = 'December 31, 2014'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746916010353/a2227293z10-k.htm'\n",
    "date = 'December 31, 2015'\n",
    "\n",
    "qtr_date = date\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables_manual(soup_content, qtr_date):\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "    count = 0\n",
    "\n",
    "    for tag in soup_content.find_all(text=consolidated_schedule_regex):\n",
    "        # print(len(soup_content.find_all(text=consolidated_schedule_regex)))\n",
    "        next_line_text = tag.next.text.strip()\n",
    "        date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line_text = tag.find_next(\n",
    "                text=re.compile(date_regex_pattern)).text\n",
    "            date_str = re.search(date_regex_pattern, next_line_text)\n",
    "\n",
    "        if date_str is None:\n",
    "            next_line = tag.next.text.strip()\n",
    "            date_str = re.search(date_regex_pattern, next_line)\n",
    "\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                count += 1\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table:\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2013'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2014'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Food and Beverage', re.IGNORECASE)):\n",
    "                            break\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2015'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2016'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Computers and Electronics', re.IGNORECASE)):\n",
    "                            break\n",
    "\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables_manual(content, qtr_date)\n",
    "master_table.to_csv('example.csv')\n",
    "\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "December 31, 2015\n",
      "December 31, 2014\n",
      "(647, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company(1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interest(6)(12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acquisition  Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amortized  Cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair  Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percentage  of Net  Assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Funds and Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIC Flex, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership units (0.94 units)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/7/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covestia Capital Partners, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership interest (47.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/17/2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1862</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCI Equity, LLC(8)(9)(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Member interest (100.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/1/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Computers and Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Everspin Technologies, Inc.(25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designer and manufacturer of computer memory s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First lien senior secured loan ($8,000 par due...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.75% (Libor + 7.75%/M)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840</td>\n",
       "      <td>(5)(21)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warrant to purchase up to 480,000 shares of Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>(5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0   1   \\\n",
       "0                           Company(1) NaN   \n",
       "1        Investment Funds and Vehicles NaN   \n",
       "2                     CIC Flex, LP(10) NaN   \n",
       "3    Covestia Capital Partners, LP(10) NaN   \n",
       "4            HCI Equity, LLC(8)(9)(10) NaN   \n",
       "..                                 ...  ..   \n",
       "642                                NaN NaN   \n",
       "643          Computers and Electronics NaN   \n",
       "644    Everspin Technologies, Inc.(25) NaN   \n",
       "645                                NaN NaN   \n",
       "646                                NaN NaN   \n",
       "\n",
       "                                                    2   3   \\\n",
       "0                                 Business Description NaN   \n",
       "1                                                  NaN NaN   \n",
       "2                               Investment partnership NaN   \n",
       "3                               Investment partnership NaN   \n",
       "4                                   Investment company NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  Designer and manufacturer of computer memory s... NaN   \n",
       "645                                                NaN NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                                                    4   5   \\\n",
       "0                                           Investment NaN   \n",
       "1                                                  NaN NaN   \n",
       "2               Limited partnership units (0.94 units) NaN   \n",
       "3       Limited partnership interest (47.00% interest) NaN   \n",
       "4                   Member interest (100.00% interest) NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  First lien senior secured loan ($8,000 par due... NaN   \n",
       "645  Warrant to purchase up to 480,000 shares of Se... NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                          6   7                  8          9   \\\n",
       "0            Interest(6)(12) NaN  Acquisition  Date        NaN   \n",
       "1                        NaN NaN                NaN        NaN   \n",
       "2                        NaN NaN                NaN   9/7/2007   \n",
       "3                        NaN NaN                NaN  6/17/2008   \n",
       "4                        NaN NaN                NaN   4/1/2010   \n",
       "..                       ...  ..                ...        ...   \n",
       "642                      NaN NaN                NaN        NaN   \n",
       "643                      NaN NaN                NaN        NaN   \n",
       "644  8.75% (Libor + 7.75%/M) NaN                NaN   6/5/2015   \n",
       "645                      NaN NaN                NaN   6/5/2015   \n",
       "646                      NaN NaN                NaN        NaN   \n",
       "\n",
       "                  10  11           12  13                          14     15  \\\n",
       "0    Amortized  Cost NaN  Fair  Value NaN  Percentage  of Net  Assets    NaN   \n",
       "1                NaN NaN          NaN NaN                         NaN    NaN   \n",
       "2                NaN NaN            - NaN                         NaN    263   \n",
       "3                NaN NaN          487 NaN                         NaN   1862   \n",
       "4                NaN NaN            - NaN                         NaN    127   \n",
       "..               ...  ..          ...  ..                         ...    ...   \n",
       "642              NaN NaN        10659 NaN                         NaN  13534   \n",
       "643              NaN NaN          NaN NaN                         NaN    NaN   \n",
       "644              NaN NaN         7533 NaN                         NaN   7840   \n",
       "645              NaN NaN          355 NaN                         NaN    355   \n",
       "646              NaN NaN         7888 NaN                         NaN   8195   \n",
       "\n",
       "          16  17    18   19  \n",
       "0        NaN NaN   NaN  NaN  \n",
       "1        NaN NaN   NaN  NaN  \n",
       "2        (2) NaN   NaN  NaN  \n",
       "3        (2) NaN   NaN  NaN  \n",
       "4        NaN NaN   NaN  NaN  \n",
       "..       ...  ..   ...  ...  \n",
       "642      NaN NaN  0.26    %  \n",
       "643      NaN NaN   NaN  NaN  \n",
       "644  (5)(21) NaN   NaN  NaN  \n",
       "645      (5) NaN   NaN  NaN  \n",
       "646      NaN NaN   NaN  NaN  \n",
       "\n",
       "[647 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775023000036/arcc-20230630.htm'\n",
    "# date = 'June 30, 2023'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "# date = 'March 31, 2019'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746914001349/a2218339z10-k.htm'\n",
    "date = 'December 31, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000015/arccq1-1810q.htm'\n",
    "# date = 'March 31, 2018'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465913080832/a13-19678_110q.htm'\n",
    "# date = 'September 30, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000007/arccq4-1710k.htm'\n",
    "# date = 'December 31, 2017'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746915001240/a2222984z10-k.htm'\n",
    "date = 'December 31, 2014'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746916010353/a2227293z10-k.htm'\n",
    "date = 'December 31, 2015'\n",
    "\n",
    "qtr_date = date\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables_manual(soup_content, qtr_date):\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    master_table = None\n",
    "    for tag in soup_content.find_all(text=re.compile(date_regex_pattern2)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.text)\n",
    "        find_next = tag.find_next().text\n",
    "        next_line = tag.next.text\n",
    "        if re.search('dollar amounts', find_next) or re.search('dollar amounts', next_line):\n",
    "            print(date_str.group(1))\n",
    "            if date_str is not None:\n",
    "                date_str = str(date_str.group(1))\n",
    "                date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table:\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2013'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2014'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Food and Beverage', re.IGNORECASE)):\n",
    "                            break\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2015'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2016'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Computers and Electronics', re.IGNORECASE)):\n",
    "                            break\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables_manual(content, qtr_date)\n",
    "master_table.to_csv('example.csv')\n",
    "\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company(1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interest(6)(12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acquisition  Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amortized  Cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair  Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percentage  of Net  Assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Funds and Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIC Flex, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership units (0.94 units)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/7/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covestia Capital Partners, LP(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Limited partnership interest (47.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/17/2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1862</td>\n",
       "      <td>(2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCI Equity, LLC(8)(9)(10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Member interest (100.00% interest)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/1/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Computers and Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Everspin Technologies, Inc.(25)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designer and manufacturer of computer memory s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First lien senior secured loan ($8,000 par due...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.75% (Libor + 7.75%/M)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840</td>\n",
       "      <td>(5)(21)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warrant to purchase up to 480,000 shares of Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "      <td>(5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0   1   \\\n",
       "0                           Company(1) NaN   \n",
       "1        Investment Funds and Vehicles NaN   \n",
       "2                     CIC Flex, LP(10) NaN   \n",
       "3    Covestia Capital Partners, LP(10) NaN   \n",
       "4            HCI Equity, LLC(8)(9)(10) NaN   \n",
       "..                                 ...  ..   \n",
       "642                                NaN NaN   \n",
       "643          Computers and Electronics NaN   \n",
       "644    Everspin Technologies, Inc.(25) NaN   \n",
       "645                                NaN NaN   \n",
       "646                                NaN NaN   \n",
       "\n",
       "                                                    2   3   \\\n",
       "0                                 Business Description NaN   \n",
       "1                                                  NaN NaN   \n",
       "2                               Investment partnership NaN   \n",
       "3                               Investment partnership NaN   \n",
       "4                                   Investment company NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  Designer and manufacturer of computer memory s... NaN   \n",
       "645                                                NaN NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                                                    4   5   \\\n",
       "0                                           Investment NaN   \n",
       "1                                                  NaN NaN   \n",
       "2               Limited partnership units (0.94 units) NaN   \n",
       "3       Limited partnership interest (47.00% interest) NaN   \n",
       "4                   Member interest (100.00% interest) NaN   \n",
       "..                                                 ...  ..   \n",
       "642                                                NaN NaN   \n",
       "643                                                NaN NaN   \n",
       "644  First lien senior secured loan ($8,000 par due... NaN   \n",
       "645  Warrant to purchase up to 480,000 shares of Se... NaN   \n",
       "646                                                NaN NaN   \n",
       "\n",
       "                          6   7                  8          9   \\\n",
       "0            Interest(6)(12) NaN  Acquisition  Date        NaN   \n",
       "1                        NaN NaN                NaN        NaN   \n",
       "2                        NaN NaN                NaN   9/7/2007   \n",
       "3                        NaN NaN                NaN  6/17/2008   \n",
       "4                        NaN NaN                NaN   4/1/2010   \n",
       "..                       ...  ..                ...        ...   \n",
       "642                      NaN NaN                NaN        NaN   \n",
       "643                      NaN NaN                NaN        NaN   \n",
       "644  8.75% (Libor + 7.75%/M) NaN                NaN   6/5/2015   \n",
       "645                      NaN NaN                NaN   6/5/2015   \n",
       "646                      NaN NaN                NaN        NaN   \n",
       "\n",
       "                  10  11           12  13                          14     15  \\\n",
       "0    Amortized  Cost NaN  Fair  Value NaN  Percentage  of Net  Assets    NaN   \n",
       "1                NaN NaN          NaN NaN                         NaN    NaN   \n",
       "2                NaN NaN            - NaN                         NaN    263   \n",
       "3                NaN NaN          487 NaN                         NaN   1862   \n",
       "4                NaN NaN            - NaN                         NaN    127   \n",
       "..               ...  ..          ...  ..                         ...    ...   \n",
       "642              NaN NaN        10659 NaN                         NaN  13534   \n",
       "643              NaN NaN          NaN NaN                         NaN    NaN   \n",
       "644              NaN NaN         7533 NaN                         NaN   7840   \n",
       "645              NaN NaN          355 NaN                         NaN    355   \n",
       "646              NaN NaN         7888 NaN                         NaN   8195   \n",
       "\n",
       "          16  17    18   19  \n",
       "0        NaN NaN   NaN  NaN  \n",
       "1        NaN NaN   NaN  NaN  \n",
       "2        (2) NaN   NaN  NaN  \n",
       "3        (2) NaN   NaN  NaN  \n",
       "4        NaN NaN   NaN  NaN  \n",
       "..       ...  ..   ...  ...  \n",
       "642      NaN NaN  0.26    %  \n",
       "643      NaN NaN   NaN  NaN  \n",
       "644  (5)(21) NaN   NaN  NaN  \n",
       "645      (5) NaN   NaN  NaN  \n",
       "646      NaN NaN   NaN  NaN  \n",
       "\n",
       "[647 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775023000036/arcc-20230630.htm'\n",
    "# date = 'June 30, 2023'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775019000013/arccq1-1910q.htm'\n",
    "# date = 'March 31, 2019'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746914001349/a2218339z10-k.htm'\n",
    "# date = 'December 31, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000015/arccq1-1810q.htm'\n",
    "# date = 'March 31, 2018'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000110465913080832/a13-19678_110q.htm'\n",
    "# date = 'September 30, 2013'\n",
    "# url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775018000007/arccq4-1710k.htm'\n",
    "# date = 'December 31, 2017'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746915001240/a2222984z10-k.htm'\n",
    "date = 'December 31, 2014'\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000104746916010353/a2227293z10-k.htm'\n",
    "date = 'December 31, 2015'\n",
    "\n",
    "qtr_date = date\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')\n",
    "\n",
    "\n",
    "def extract_tables_manual(soup_content, qtr_date):\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "\n",
    "    for tag in soup_content.find_all(text=re.compile(date_regex_pattern2)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.text)\n",
    "        find_next = tag.find_next().text\n",
    "        next_line = tag.next.text\n",
    "        if re.search('dollar amounts', find_next) or re.search('dollar amounts', next_line):\n",
    "            if re.search('dollar amounts', next_line):\n",
    "                if date_str is not None:\n",
    "                    date_str = str(date_str.group(1))\n",
    "                    date_str = unicodedata.normalize('NFKD', date_str)\n",
    "                if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                    html_table = tag.find_next('table')\n",
    "                    while html_table:\n",
    "                        new_table = pd.read_html(\n",
    "                            html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                        new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                            'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                        new_table = new_table.replace(\n",
    "                            r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                        new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                        if master_table is None:\n",
    "                            master_table = new_table\n",
    "                        else:\n",
    "                            master_table = pd.concat(\n",
    "                                [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                        if date_str.replace(',', '').strip().lower() in 'December 31, 2013'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2014'.replace(',', '').strip().lower():\n",
    "                            if html_table.find(text=re.compile(r'Food and Beverage', re.IGNORECASE)):\n",
    "                                break\n",
    "                        if date_str.replace(',', '').strip().lower() in 'December 31, 2015'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2016'.replace(',', '').strip().lower():\n",
    "                            if html_table.find(text=re.compile(r'Computers and Electronics', re.IGNORECASE)):\n",
    "                                break\n",
    "                        html_table = html_table.find_next('table')\n",
    "            else:\n",
    "                if date_str is not None:\n",
    "                    date_str = str(date_str.group(1))\n",
    "                    date_str = unicodedata.normalize('NFKD', date_str)\n",
    "                if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                    html_table = tag.find_next('table')\n",
    "                    if master_table is None:\n",
    "                        master_table = pd.read_html(\n",
    "                            html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                        master_table = master_table.applymap(lambda x: unicodedata.normalize(\n",
    "                            'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                        master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan,\n",
    "                                                                                                  regex=True)\n",
    "                        master_table = master_table.dropna(how='all', axis=0)\n",
    "                    else:\n",
    "                        new_table = pd.read_html(\n",
    "                            html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                        new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                            'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                        new_table = new_table.replace(r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan,\n",
    "                                                                                            regex=True)\n",
    "                        new_table = new_table.dropna(how='all', axis=0)\n",
    "                        # print('head')\n",
    "                        # print(new_table.head()) # text\n",
    "                        master_table = master_table.append(\n",
    "                            new_table.dropna(how='all', axis=0).reset_index(\n",
    "                                drop=True).drop(index=0),\n",
    "                            ignore_index=True)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "master_table = extract_tables_manual(content, qtr_date)\n",
    "master_table.to_csv('example.csv')\n",
    "\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
