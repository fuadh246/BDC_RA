{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROSSESING TABEELS NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html5lib\n",
    "import requests\n",
    "from openpyxl import Workbook\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_trim(content, content_type):\n",
    "    if content_type == 'HTML':\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    else:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    for tag in soup.recursiveChildGenerator():\n",
    "        try:\n",
    "            tag.attrs = None\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    for linebreak in soup.find_all('br'):\n",
    "        linebreak.extract()\n",
    "    return soup\n",
    "\n",
    "\n",
    "def remove_multiple_spaces(string):\n",
    "    pattern = r'\\s+'\n",
    "    replaced_string = re.sub(pattern, ' ', string)\n",
    "    return replaced_string\n",
    "\n",
    "\n",
    "def find_qrt_date(content):\n",
    "    qtr_date = content.find_all(text=re.compile(\n",
    "        r'for\\s+(the\\s+)?(fiscal\\s+)?year\\s+ended\\s+|for\\s+the\\s+quarter\\s+ended\\s+|for\\s+the\\s+quarterly\\s+period\\s+ended\\s+', re.IGNORECASE))\n",
    "    qtr_match = re.search(\n",
    "        r'([A-Za-z]+)\\s+(\\d{1,2}),\\s+(\\d{4})', qtr_date[0].replace('\\n', ''))\n",
    "    if qtr_match is None:\n",
    "        qtr_match = qtr_match = re.search(\n",
    "            r'([A-Za-z]+) (\\d{1,2}), (\\d{4})', qtr_date[1])\n",
    "    return remove_multiple_spaces(str(qtr_match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form type</th>\n",
       "      <th>Form description</th>\n",
       "      <th>Filing date</th>\n",
       "      <th>Reporting date</th>\n",
       "      <th>Filings URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>May 07, 2013</td>\n",
       "      <td>March 31, 2013</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/128775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>August 06, 2013</td>\n",
       "      <td>June 30, 2013</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/128775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>November 05, 2013</td>\n",
       "      <td>September 30, 2013</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/128775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10-K</td>\n",
       "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
       "      <td>February 26, 2014</td>\n",
       "      <td>December 31, 2013</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/128775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>May 06, 2014</td>\n",
       "      <td>March 31, 2014</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/128775...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Form type                                   Form description  \\\n",
       "10      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "11      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "12      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "13      10-K  Annual report [Section 13 and 15(d), not S-K I...   \n",
       "14      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "\n",
       "          Filing date      Reporting date  \\\n",
       "10       May 07, 2013      March 31, 2013   \n",
       "11    August 06, 2013       June 30, 2013   \n",
       "12  November 05, 2013  September 30, 2013   \n",
       "13  February 26, 2014   December 31, 2013   \n",
       "14       May 06, 2014      March 31, 2014   \n",
       "\n",
       "                                          Filings URL  \n",
       "10  https://www.sec.gov/Archives/edgar/data/128775...  \n",
       "11  https://www.sec.gov/Archives/edgar/data/128775...  \n",
       "12  https://www.sec.gov/Archives/edgar/data/128775...  \n",
       "13  https://www.sec.gov/Archives/edgar/data/128775...  \n",
       "14  https://www.sec.gov/Archives/edgar/data/128775...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'ARES CAPITAL CORP'\n",
    "}\n",
    "filing_links = pd.read_excel(\n",
    "    \"/Users/fuadhassan/Desktop/BDC_RA/ARCC/ARCC__sec_filing_links.xlsx\")\n",
    "filing_links.head()\n",
    "\n",
    "# drops all the amendment filing\n",
    "filing_links = filing_links.drop(filing_links[filing_links['Form description'].str.contains(\n",
    "    'amendment', case=False)].index).reset_index(drop=True)\n",
    "filing_links['Reporting date'] = pd.to_datetime(filing_links['Reporting date'])\n",
    "filing_links = filing_links[filing_links['Reporting date'] >= '2013-03-31']\n",
    "filing_links.head()\n",
    "\n",
    "date_columns = ['Filing date', 'Reporting date']\n",
    "for col in date_columns:\n",
    "    filing_links[col] = pd.to_datetime(filing_links[col], format='%Y-%m-%d')\n",
    "for col in date_columns:\n",
    "    filing_links[col] = filing_links[col].dt.strftime(\"%B %d, %Y\")\n",
    "filing_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42 entries, 10 to 51\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Form type         42 non-null     object\n",
      " 1   Form description  42 non-null     object\n",
      " 2   Filing date       42 non-null     object\n",
      " 3   Reporting date    42 non-null     object\n",
      " 4   Filings URL       42 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "filing_links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(soup_content, qtr_date):\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    master_table = None\n",
    "    all_tags = soup_content.find_all(True)\n",
    "\n",
    "    for tag in soup_content.find_all(text=re.compile(date_regex_pattern2)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.text)\n",
    "        find_next = tag.find_next().text\n",
    "        next_line = tag.next.text\n",
    "        if re.search('dollar amounts', find_next) or re.search('dollar amounts', next_line):\n",
    "            if date_str is not None:\n",
    "                date_str = str(date_str.group(1))\n",
    "                date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                html_table = tag.find_next('table')\n",
    "\n",
    "                new_table = pd.read_html(\n",
    "                    html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                    'NFKD', x.strip().strip(u'\\u200b').replace('â€”', '-')) if type(x) == str else x)\n",
    "                new_table = new_table.replace(\n",
    "                    r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                if master_table is None:\n",
    "                    master_table = new_table\n",
    "                else:\n",
    "                    master_table = pd.concat(\n",
    "                        [master_table, new_table], ignore_index=True)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "def extract_tables_manual(soup_content, qtr_date):\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    master_table = None\n",
    "    for tag in soup_content.find_all(text=re.compile(date_regex_pattern2)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.text)\n",
    "        find_next = tag.find_next().text\n",
    "        next_line = tag.next.text\n",
    "        if re.search('dollar amounts', find_next) or re.search('dollar amounts', next_line):\n",
    "            print(date_str.group(1))\n",
    "            if date_str is not None:\n",
    "                date_str = str(date_str.group(1))\n",
    "                date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            if qtr_date.replace(',', '').strip().lower() in date_str.replace(',', '').strip().lower():\n",
    "                html_table = tag.find_next('table')\n",
    "                while html_table:\n",
    "                    new_table = pd.read_html(\n",
    "                        html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                    new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('â€”', '-')) if type(x) == str else x)\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if master_table is None:\n",
    "                        master_table = new_table\n",
    "                    else:\n",
    "                        master_table = pd.concat(\n",
    "                            [master_table, new_table], ignore_index=True)\n",
    "\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2013'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2014'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Food and Beverage', re.IGNORECASE)):\n",
    "                            break\n",
    "                    if date_str.replace(',', '').strip().lower() in 'December 31, 2015'.replace(',', '').strip().lower() or date_str.replace(',', '').strip().lower() in 'December 31, 2016'.replace(',', '').strip().lower():\n",
    "                        if html_table.find(text=re.compile(r'Computers and Electronics', re.IGNORECASE)):\n",
    "                            break\n",
    "                    html_table = html_table.find_next('table')\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/edgar/data/1287750/000128775023000036/arcc-20230630.htm'\n",
    "date = 'June 30, 2023'\n",
    "response = requests.get(url, headers=headers)\n",
    "content = parse_and_trim(response.content, 'HTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company (1)</th>\n",
       "      <th>Business Description</th>\n",
       "      <th>Investment</th>\n",
       "      <th>Coupon (3)</th>\n",
       "      <th>Reference (7)</th>\n",
       "      <th>Spread (3)</th>\n",
       "      <th>Acquisition Date</th>\n",
       "      <th>Maturity Date</th>\n",
       "      <th>Shares/Units</th>\n",
       "      <th>Principal</th>\n",
       "      <th>NaN</th>\n",
       "      <th>Amortized Cost</th>\n",
       "      <th>Fair Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software and Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2U, Inc.</td>\n",
       "      <td>Provider of course design and learning managem...</td>\n",
       "      <td>First lien senior secured loan</td>\n",
       "      <td>11.32  %</td>\n",
       "      <td>SOFR (M)</td>\n",
       "      <td>6.50  %</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>12/2026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AffiniPay Midco, LLC and AffiniPay Intermediat...</td>\n",
       "      <td>Payment processing solution provider</td>\n",
       "      <td>First lien senior secured loan</td>\n",
       "      <td>10.20  %</td>\n",
       "      <td>SOFR (A)</td>\n",
       "      <td>5.50  %</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>06/2028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AffiniPay Midco, LLC and AffiniPay Intermediat...</td>\n",
       "      <td>Payment processing solution provider</td>\n",
       "      <td>First lien senior secured loan</td>\n",
       "      <td>10.39  %</td>\n",
       "      <td>SOFR (A)</td>\n",
       "      <td>5.50  %</td>\n",
       "      <td>06/2022</td>\n",
       "      <td>06/2028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AffiniPay Midco, LLC and AffiniPay Intermediat...</td>\n",
       "      <td>Payment processing solution provider</td>\n",
       "      <td>Senior subordinated loan</td>\n",
       "      <td>15.06  % PIK</td>\n",
       "      <td>SOFR (Q)</td>\n",
       "      <td>10.00  %</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>06/2030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Flinn Scientific, Inc. and WCI-Quantum Holding...</td>\n",
       "      <td>Distributor of instructional products, service...</td>\n",
       "      <td>First lien senior secured loan</td>\n",
       "      <td>11.00  %</td>\n",
       "      <td>SOFR (Q)</td>\n",
       "      <td>5.50  %</td>\n",
       "      <td>08/2018</td>\n",
       "      <td>08/2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Flinn Scientific, Inc. and WCI-Quantum Holding...</td>\n",
       "      <td>Distributor of instructional products, service...</td>\n",
       "      <td>Series A preferred stock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Flinn Scientific, Inc. and WCI-Quantum Holding...</td>\n",
       "      <td>Distributor of instructional products, service...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.5</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Flinn Scientific, Inc. and WCI-Quantum Holding...</td>\n",
       "      <td>Distributor of instructional products, service...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.7</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Total Investments</td>\n",
       "      <td>Distributor of instructional products, service...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21685.6</td>\n",
       "      <td>21496.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Company (1)  \\\n",
       "0                                 Software and Services   \n",
       "1                                              2U, Inc.   \n",
       "2     AffiniPay Midco, LLC and AffiniPay Intermediat...   \n",
       "3     AffiniPay Midco, LLC and AffiniPay Intermediat...   \n",
       "4     AffiniPay Midco, LLC and AffiniPay Intermediat...   \n",
       "...                                                 ...   \n",
       "1502  Flinn Scientific, Inc. and WCI-Quantum Holding...   \n",
       "1503  Flinn Scientific, Inc. and WCI-Quantum Holding...   \n",
       "1504  Flinn Scientific, Inc. and WCI-Quantum Holding...   \n",
       "1505  Flinn Scientific, Inc. and WCI-Quantum Holding...   \n",
       "1506                                  Total Investments   \n",
       "\n",
       "                                   Business Description  \\\n",
       "0                                                   NaN   \n",
       "1     Provider of course design and learning managem...   \n",
       "2                  Payment processing solution provider   \n",
       "3                  Payment processing solution provider   \n",
       "4                  Payment processing solution provider   \n",
       "...                                                 ...   \n",
       "1502  Distributor of instructional products, service...   \n",
       "1503  Distributor of instructional products, service...   \n",
       "1504  Distributor of instructional products, service...   \n",
       "1505  Distributor of instructional products, service...   \n",
       "1506  Distributor of instructional products, service...   \n",
       "\n",
       "                          Investment    Coupon (3) Reference (7) Spread (3)  \\\n",
       "0                                NaN           NaN           NaN        NaN   \n",
       "1     First lien senior secured loan      11.32  %      SOFR (M)    6.50  %   \n",
       "2     First lien senior secured loan      10.20  %      SOFR (A)    5.50  %   \n",
       "3     First lien senior secured loan      10.39  %      SOFR (A)    5.50  %   \n",
       "4           Senior subordinated loan  15.06  % PIK      SOFR (Q)   10.00  %   \n",
       "...                              ...           ...           ...        ...   \n",
       "1502  First lien senior secured loan      11.00  %      SOFR (Q)    5.50  %   \n",
       "1503        Series A preferred stock           NaN           NaN        NaN   \n",
       "1504                             NaN           NaN           NaN        NaN   \n",
       "1505                             NaN           NaN           NaN        NaN   \n",
       "1506                             NaN           NaN           NaN        NaN   \n",
       "\n",
       "     Acquisition Date Maturity Date  Shares/Units  Principal  NaN  \\\n",
       "0                 NaN           NaN           0.0        0.0  NaN   \n",
       "1             01/2023       12/2026           0.0        0.0  4.7   \n",
       "2             02/2020       06/2028           0.0       63.0  NaN   \n",
       "3             06/2022       06/2028           0.0      120.0  NaN   \n",
       "4             02/2020       06/2030           0.0       61.0  NaN   \n",
       "...               ...           ...           ...        ...  ...   \n",
       "1502          08/2018       08/2024           0.0        1.1  NaN   \n",
       "1503          10/2014           NaN        1272.0        0.0  NaN   \n",
       "1504              NaN           NaN           0.0        0.0  NaN   \n",
       "1505              NaN           NaN           0.0        0.0  NaN   \n",
       "1506              NaN           NaN           0.0        0.0  NaN   \n",
       "\n",
       "      Amortized Cost  Fair Value  \n",
       "0                0.0         0.0  \n",
       "1                4.4         4.5  \n",
       "2               63.0        61.8  \n",
       "3              118.0       117.6  \n",
       "4               61.0        59.8  \n",
       "...              ...         ...  \n",
       "1502             1.1         1.1  \n",
       "1503             0.7         1.4  \n",
       "1504            41.5        42.2  \n",
       "1505            50.7        51.4  \n",
       "1506         21685.6     21496.5  \n",
       "\n",
       "[1507 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_table(soi_table_df, append_str):\n",
    "    soi_table_df = soi_table_df.replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=1)\n",
    "    soi_table_df = soi_table_df.dropna(\n",
    "        how='all', axis=0).reset_index(drop=True)\n",
    "    # print('1: ' + str(soi_table_df.shape))\n",
    "\n",
    "    # Separate header and data\n",
    "    soi_table_header = soi_table_df.iloc[0].dropna(how='any')\n",
    "    soi_table_data_df = soi_table_df.rename(\n",
    "        columns=soi_table_df.iloc[0]).drop(soi_table_df.index[0])\n",
    "    # print('2: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # drops all the rows that contains header\n",
    "    soi_table_data_df = soi_table_data_df[soi_table_data_df[soi_table_data_df.columns[0]]\n",
    "                                          != soi_table_data_df.columns[0]]\n",
    "\n",
    "    # print('3: ' + str(soi_table_data_df.shape))\n",
    "    # Initialize the new column with the first non-empty \"Company (1)\" value\n",
    "\n",
    "    # Drop rows with only two non-null values becuase all the subtotal contain 2 value only\n",
    "    # soi_table_data_df = soi_table_data_df.dropna(thresh=3)\n",
    "    # soi_table_data_df = soi_table_data_df.dropna(thresh=3)\n",
    "    row_lengths = soi_table_data_df.apply(lambda row: len(row), axis=1)\n",
    "    soi_table_data_df = soi_table_data_df[row_lengths != 2]\n",
    "\n",
    "    # print('4: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # replace all the - in the data table with 0\n",
    "    soi_table_data_df = soi_table_data_df.replace('-', 0, regex=False)\n",
    "\n",
    "    # fix the all the nan value column , Amortized Cost, Fair Value\n",
    "    columns_to_fill = ['Amortized Cost', 'Fair Value']\n",
    "    for col in columns_to_fill:\n",
    "        col_index = soi_table_data_df.columns.str.replace(\n",
    "            ' ', '').get_loc(col.replace(' ', ''))\n",
    "        next_col_index = col_index + 1\n",
    "        for i in range(len(soi_table_data_df)):\n",
    "            current_value = soi_table_data_df.iat[i, col_index]\n",
    "            if pd.isna(current_value) and next_col_index < len(soi_table_data_df.columns):\n",
    "                next_valid_index = next((j for j, v in enumerate(\n",
    "                    soi_table_data_df.iloc[i, next_col_index:], start=next_col_index) if pd.notna(v)), None)\n",
    "\n",
    "                if next_valid_index is not None:\n",
    "                    next_value = soi_table_data_df.iat[i, next_valid_index]\n",
    "                    soi_table_data_df.iat[i, col_index] = next_value\n",
    "                    soi_table_data_df.iat[i, next_valid_index] = pd.NA\n",
    "\n",
    "    # drops everything after FairValue\n",
    "    if 'FairValue' in soi_table_data_df.columns.str.replace(' ', ''):\n",
    "        start_index = soi_table_data_df.columns.str.replace(\n",
    "            ' ', '').get_loc('FairValue')\n",
    "        soi_table_data_df = soi_table_data_df.iloc[:, :start_index+1]\n",
    "\n",
    "    # Drop rows with only two non-null values this one recheacks\n",
    "    # soi_table_data_df = soi_table_data_df.dropna(thresh=3)\n",
    "\n",
    "    # Forward fill the first two columns\n",
    "    col_indices = [0, 1]\n",
    "    soi_table_data_df.iloc[:, col_indices] = soi_table_data_df.iloc[:, col_indices].fillna(\n",
    "        method='ffill')\n",
    "    # print('7: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # Drop rows with all missing values\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=1)\n",
    "    # print('5: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # Drop columns with all missing values\n",
    "    soi_table_data_df = soi_table_data_df.dropna(how='all', axis=1)\n",
    "    # print('6: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # fill all the nan with 0\n",
    "    # soi_table_data_df = soi_table_data_df.fillna(0)\n",
    "\n",
    "    # converts to number\n",
    "    # cols_to_convert = ['Shares/Units', 'Principal',\n",
    "    #                    'Amortized Cost', 'Fair Value']\n",
    "    # for col in cols_to_convert:\n",
    "    #     if col.replace(' ', '') in soi_table_data_df.columns.str.replace(' ', ''):\n",
    "    #         col_index = soi_table_data_df.columns.str.replace(\n",
    "    #             ' ', '').get_loc(col.replace(' ', ''))\n",
    "    #         soi_table_data_df.iloc[:, col_index] = pd.to_numeric(\n",
    "    #             soi_table_data_df.iloc[:, col_index], errors='coerce').fillna(0)\n",
    "\n",
    "    cols_to_convert = ['Shares/Units', 'Principal',\n",
    "                       'Amortized Cost', 'Fair Value']\n",
    "    for col in cols_to_convert:\n",
    "        if col.replace(' ', '') in soi_table_data_df.columns.str.replace(' ', ''):\n",
    "            col_index = soi_table_data_df.columns.str.replace(\n",
    "                ' ', '').get_loc(col.replace(' ', ''))\n",
    "            converted_data = pd.to_numeric(\n",
    "                soi_table_data_df.iloc[:, col_index], errors='coerce').fillna(0)\n",
    "            soi_table_data_df[soi_table_data_df.columns[col_index]\n",
    "                              ] = converted_data\n",
    "\n",
    "    soi_table_data_df = soi_table_data_df.reset_index(drop=True)\n",
    "\n",
    "    # keeping the total for now to check if the total is right\n",
    "    # Drop rows based on regex pattern (e.g., 'subtotal' or 'total')\n",
    "    # pattern = r'^([Ss]ubtotal)|([Tt]otal)'\n",
    "    # mask = soi_table_data_df.apply(lambda row: row.astype(\n",
    "    #     str).str.contains(pattern, case=False, na=False)).any(axis=1)\n",
    "    # soi_table_data_df = soi_table_data_df[~mask]\n",
    "    # # print('4: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # we dont need this here because we are dropping subtotal before\n",
    "    # Drop rows labeled as subtotals\n",
    "    # subtotal_rows = soi_table_data_df[soi_table_data_df['Company (1)'].str.replace(' ', '').str.contains(\n",
    "    #     'subtotal', case=False, na=False)]\n",
    "    # soi_table_data_df = soi_table_data_df[~soi_table_data_df.index.isin(\n",
    "    #     subtotal_rows.index)]\n",
    "    # print('3: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    # we dont need this here because we are dropping subtotal before\n",
    "    # columns_to_drop = []\n",
    "    # for column in soi_table_data_df.columns:\n",
    "    #     # Check for NaN values in the column\n",
    "    #     # Use .item() to get a single boolean value\n",
    "    #     if soi_table_data_df[column].isna().any().item():\n",
    "    #         columns_to_drop.append(column)\n",
    "    # soi_table_data_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # print('Final: ' + str(soi_table_data_df.shape))\n",
    "\n",
    "    return soi_table_data_df\n",
    "\n",
    "\n",
    "master_table = extract_tables(content, date)\n",
    "process_table_ = process_table(master_table, \"\")\n",
    "process_table_.to_excel(\"example.xlsx\")\n",
    "process_table_.to_csv('example.csv')\n",
    "process_table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
