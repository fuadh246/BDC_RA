{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html5lib\n",
    "import requests\n",
    "from openpyxl import Workbook\n",
    "from datetime import datetime\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "def parse_and_trim(content, content_type):\n",
    "    if content_type == 'HTML':\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    else:\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "    for tag in soup.recursiveChildGenerator():\n",
    "        try:\n",
    "            tag.attrs = None\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    for linebreak in soup.find_all('br'):\n",
    "        linebreak.extract()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form type</th>\n",
       "      <th>Form description</th>\n",
       "      <th>Filing date</th>\n",
       "      <th>Reporting date</th>\n",
       "      <th>Act</th>\n",
       "      <th>Film number</th>\n",
       "      <th>Accession number</th>\n",
       "      <th>Filings URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>May 03, 2013</td>\n",
       "      <td>March 31, 2013</td>\n",
       "      <td>34</td>\n",
       "      <td>13810352</td>\n",
       "      <td>0001144204-13-026113</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/147676...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>August 08, 2013</td>\n",
       "      <td>June 30, 2013</td>\n",
       "      <td>34</td>\n",
       "      <td>131020072</td>\n",
       "      <td>0001144204-13-043799</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/147676...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-K</td>\n",
       "      <td>Annual report [Section 13 and 15(d), not S-K I...</td>\n",
       "      <td>December 03, 2013</td>\n",
       "      <td>September 30, 2013</td>\n",
       "      <td>34</td>\n",
       "      <td>131254591</td>\n",
       "      <td>0001144204-13-065322</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>February 06, 2014</td>\n",
       "      <td>December 31, 2013</td>\n",
       "      <td>34</td>\n",
       "      <td>14578102</td>\n",
       "      <td>0001144204-14-006255</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>Quarterly report [Sections 13 or 15(d)]</td>\n",
       "      <td>May 08, 2014</td>\n",
       "      <td>March 31, 2014</td>\n",
       "      <td>34</td>\n",
       "      <td>14823110</td>\n",
       "      <td>0001144204-14-028416</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000147...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Form type                                   Form description  \\\n",
       "0      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "1      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "2      10-K  Annual report [Section 13 and 15(d), not S-K I...   \n",
       "3      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "4      10-Q            Quarterly report [Sections 13 or 15(d)]   \n",
       "\n",
       "         Filing date      Reporting date  Act  Film number  \\\n",
       "0       May 03, 2013      March 31, 2013   34     13810352   \n",
       "1    August 08, 2013       June 30, 2013   34    131020072   \n",
       "2  December 03, 2013  September 30, 2013   34    131254591   \n",
       "3  February 06, 2014   December 31, 2013   34     14578102   \n",
       "4       May 08, 2014      March 31, 2014   34     14823110   \n",
       "\n",
       "       Accession number                                        Filings URL  \n",
       "0  0001144204-13-026113  https://www.sec.gov/Archives/edgar/data/147676...  \n",
       "1  0001144204-13-043799  https://www.sec.gov/Archives/edgar/data/147676...  \n",
       "2  0001144204-13-065322  https://www.sec.gov/Archives/edgar/data/000147...  \n",
       "3  0001144204-14-006255  https://www.sec.gov/Archives/edgar/data/000147...  \n",
       "4  0001144204-14-028416  https://www.sec.gov/Archives/edgar/data/000147...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'GOLUB CAPITAL BDC, Inc.'\n",
    "}\n",
    "filing_links = pd.read_excel(\n",
    "    \"../GBDC__sec_filing_links.xlsx\")\n",
    "filing_links.head(5)\n",
    "date_columns = ['Filing date', 'Reporting date']\n",
    "for col in date_columns:\n",
    "    filing_links[col] = pd.to_datetime(filing_links[col], format='%Y-%m-%d')\n",
    "for col in date_columns:\n",
    "    filing_links[col] = filing_links[col].dt.strftime(\"%B %d, %Y\")\n",
    "filing_links.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is the OG one\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    for tag in soup_content.find_all(text=re.compile(consolidated_schedule_regex)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.find_next().text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern1, tag.next.text)\n",
    "        print(date_str)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            qtr_date_cleaned = qtr_date.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            date_str_cleaned = date_str.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            print(qtr_date_cleaned, date_str_cleaned)\n",
    "\n",
    "            if qtr_date_cleaned == date_str_cleaned:\n",
    "                html_table = tag.find_next('table')\n",
    "                new_table = pd.read_html(\n",
    "                    html_table.prettify(), skiprows=0, flavor='bs4')[0]\n",
    "                new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                    'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                new_table = new_table.replace(\n",
    "                    r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                if master_table is None:\n",
    "                    master_table = new_table\n",
    "                else:\n",
    "                    master_table = pd.concat(\n",
    "                        [master_table, new_table], ignore_index=True)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "\n",
    "    return master_table\n",
    "\n",
    "\n",
    "path = '/Users/fuadhassan/Desktop/BDC_RA/GBDC/GBDC_Investment.xlsx'\n",
    "writer = pd.ExcelWriter(path, engine='openpyxl')\n",
    "for qtr_date, html_link in zip(filing_links['Reporting date'], filing_links['Filings URL']):\n",
    "    print(html_link, qtr_date)\n",
    "    response = requests.get(html_link, headers=headers)\n",
    "    content = parse_and_trim(response.content, 'HTML')\n",
    "    master_table = extract_tables(content, qtr_date)\n",
    "    master_table.to_excel(\n",
    "        writer, sheet_name=qtr_date.replace(',', ''), index=False)\n",
    "    writer.book.save(path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_links = filing_links[filing_links['Reporting date']\n",
    "                            != 'September 30, 2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1476765/000114420413026113/v343181_10q.htm March 31, 2013\n",
      "March 31, 2013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "March\n",
      "31, 2013 march312013 march312013\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "September\n",
      "30, 2012 march312013 september302012\n",
      "(438, 31)\n",
      "https://www.sec.gov/Archives/edgar/data/1476765/000114420413043799/v351518_10q.htm June 30, 2013\n",
      "June 30, 2013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "June 30, 2013 june302013 june302013\n",
      "September 30, 2012 june302013 september302012\n",
      "September 30, 2012 june302013 september302012\n",
      "September 30, 2012 june302013 september302012\n",
      "September 30, 2012 june302013 september302012\n",
      "September 30, 2012 june302013 september302012\n",
      "September 30, 2012 june302013 september302012\n",
      "June 30, 2013 june302013 june302013\n",
      "(446, 31)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420413065322/v361550_10k.htm September 30, 2013\n",
      "September 30, 2013\n",
      "September 30, 2013 september302013 september302013\n",
      "IllinoisDecember 3, 2013 september302013 illinoisdecember32013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2013 september302013 september302013\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2012 september302013 september302012\n",
      "September 30, 2013 september302013 september302013\n",
      "(501, 41)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420414006255/v366851_10q.htm December 31, 2013\n",
      "December 31, 2013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "December 31, 2013 december312013 december312013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "September 30, 2013 december312013 september302013\n",
      "December 31, 2013 december312013 december312013\n",
      "(453, 31)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420414028416/v376994_10q.htm March 31, 2014\n",
      "March 31, 2014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "March 31, 2014 march312014 march312014\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "September 30, 2013 march312014 september302013\n",
      "(483, 31)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420414047524/v385529_10q.htm June 30, 2014\n",
      "June 30, 2014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "June 30, 2014 june302014 june302014\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "September 30, 2013 june302014 september302013\n",
      "(522, 27)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420414069568/v394051_10k.htm September 30, 2014\n",
      "September 30, 2014\n",
      "September 30, 2014 september302014 september302014\n",
      "IllinoisNovember 18, 2014 september302014 illinoisnovember182014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2014 september302014 september302014\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "September 30, 2013 september302014 september302013\n",
      "(543, 33)\n",
      "https://www.sec.gov/Archives/edgar/data/0001476765/000114420415006725/v400181_10q.htm December 31, 2014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#W5sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mfor\u001b[39;00m qtr_date, html_link \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(filing_links[\u001b[39m'\u001b[39m\u001b[39mReporting date\u001b[39m\u001b[39m'\u001b[39m], filing_links[\u001b[39m'\u001b[39m\u001b[39mFilings URL\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(html_link, qtr_date)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#W5sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(html_link, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     content \u001b[39m=\u001b[39m parse_and_trim(response\u001b[39m.\u001b[39mcontent, \u001b[39m'\u001b[39m\u001b[39mHTML\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#W5sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     master_table \u001b[39m=\u001b[39m extract_tables(content, qtr_date)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1368\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1369\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1370\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:317\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    319\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:278\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    280\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "data_frames_shapes = []\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    print(qtr_date)\n",
    "    if qtr_date == 'December 31, 2015' or qtr_date == 'June 30, 2016':\n",
    "        consolidated_schedule_regex = re.compile(\n",
    "            r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*(\\(.*\\)|)\\s*-.*\\s*\\(.*\\)$')\n",
    "    else:\n",
    "        consolidated_schedule_regex = re.compile(\n",
    "            r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    # date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    for tag in soup_content.find_all(text=re.compile(consolidated_schedule_regex)):\n",
    "        date_str = re.search(date_regex_pattern, tag.find_next().text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern, tag.next.text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern,\n",
    "                                 tag.find_next().next.next.next.text)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            qtr_date_cleaned = qtr_date.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            date_str_cleaned = date_str.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            print(date_str, qtr_date_cleaned, date_str_cleaned)\n",
    "\n",
    "            if qtr_date_cleaned == date_str_cleaned:\n",
    "                html_table = tag.find_next('table')\n",
    "                new_table = pd.read_html(\n",
    "                    html_table.prettify(), keep_default_na=False, skiprows=0, flavor='bs4')[0]\n",
    "                new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                    'NFKD', x.strip().strip(u'\\u200b').replace('—', '-')) if type(x) == str else x)\n",
    "                # new_table = new_table.replace(\n",
    "                #     r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                # new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                if master_table is None:\n",
    "                    master_table = new_table\n",
    "                else:\n",
    "                    master_table = pd.concat(\n",
    "                        [master_table, new_table], ignore_index=True)\n",
    "            # print(master_table)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    data_frames.append(master_table)\n",
    "    data_frames_shapes.append(master_table.shape)\n",
    "    return master_table\n",
    "\n",
    "\n",
    "# This does the job\n",
    "path = '/Users/fuadhassan/Desktop/BDC_RA/GBDC/Test_GBDC_Investment.xlsx'\n",
    "writer = pd.ExcelWriter(path, engine='openpyxl')\n",
    "for qtr_date, html_link in zip(filing_links['Reporting date'], filing_links['Filings URL']):\n",
    "    print(html_link, qtr_date)\n",
    "    response = requests.get(html_link, headers=headers)\n",
    "    content = parse_and_trim(response.content, 'HTML')\n",
    "    master_table = extract_tables(content, qtr_date)\n",
    "    master_table.to_excel(\n",
    "        writer, sheet_name=qtr_date.replace(',', ''), index=False)\n",
    "    writer.book .save(path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "data_frames_shapes = []\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    consolidated_schedule_regex = re.compile(\n",
    "        r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern1 = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    # date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    for tag in soup_content.find_all(text=re.compile(consolidated_schedule_regex)):\n",
    "        date_str = re.search(date_regex_pattern1, tag.find_next().text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern1, tag.next.text)\n",
    "        print(date_str)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            qtr_date_cleaned = qtr_date.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            date_str_cleaned = date_str.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            print(qtr_date_cleaned, date_str_cleaned)\n",
    "\n",
    "            if qtr_date_cleaned == date_str_cleaned:\n",
    "                table = tag.find_next(\"table\")\n",
    "                if table:\n",
    "                    # Extract the table data into a data frame\n",
    "                    table_data = []\n",
    "                    for row in table.find_all('tr'):\n",
    "                        # Include header cells ('th') if necessary\n",
    "                        columns = row.find_all(['th', 'td'])\n",
    "                        row_data = [column.get_text(strip=True)\n",
    "                                    for column in columns]\n",
    "                        table_data.append(row_data)\n",
    "\n",
    "                    # Create a data frame from the table data and add it to the list\n",
    "                    table_df = pd.DataFrame(table_data)\n",
    "                    new_table = table_df.applymap(lambda x: unicodedata.normalize(\n",
    "                        'NFKD', x.strip().strip(u'\\u200b').replace('—', '0').replace('%', '')) if type(x) == str else x)\n",
    "\n",
    "                    new_table = new_table.replace(\n",
    "                        r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                    table_df = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                    if len(table_df.columns) > 10:\n",
    "                        data_frames.append(table_df)\n",
    "\n",
    "                        if master_table is None:\n",
    "                            master_table = table_df\n",
    "                        else:\n",
    "                            master_table = pd.concat(\n",
    "                                [master_table, table_df], ignore_index=True)\n",
    "\n",
    "            # print(master_table)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "data_frames_shapes = []\n",
    "\n",
    "\n",
    "def extract_tables(soup_content, qtr_date):\n",
    "    master_table = None\n",
    "    print(qtr_date)\n",
    "    if qtr_date == 'December 31, 2015' or qtr_date == 'June 30, 2016':\n",
    "        consolidated_schedule_regex = re.compile(\n",
    "            r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*(\\(.*\\)|)\\s*-.*\\s*\\(.*\\)$')\n",
    "    else:\n",
    "        consolidated_schedule_regex = re.compile(\n",
    "            r'(?i)^\\s*.*\\s*CONSOLIDATED\\s+SCHEDULE(S|)\\s+OF\\s+INVESTMENTS\\s*.*\\s*$')\n",
    "    date_regex_pattern = r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})'\n",
    "    # date_regex_pattern2 = r'\\bAs\\s+of\\s+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\\b'\n",
    "    for tag in soup_content.find_all(text=re.compile(consolidated_schedule_regex)):\n",
    "        date_str = re.search(date_regex_pattern, tag.find_next().text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern, tag.next.text)\n",
    "        if date_str is None:\n",
    "            date_str = re.search(date_regex_pattern,\n",
    "                                 tag.find_next().next.next.next.text)\n",
    "        if date_str is not None:\n",
    "            date_str = str(date_str.group(1))\n",
    "            date_str = unicodedata.normalize('NFKD', date_str)\n",
    "            qtr_date_cleaned = qtr_date.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            date_str_cleaned = date_str.replace(',', '').replace(\n",
    "                ' ', '').replace('\\n', '').lower()\n",
    "            print(date_str, qtr_date_cleaned, date_str_cleaned)\n",
    "\n",
    "            if qtr_date_cleaned == date_str_cleaned:\n",
    "                html_table = tag.find_next('table')\n",
    "                new_table = pd.read_html(\n",
    "                    html_table.prettify(), keep_default_na=False, skiprows=0, flavor='bs4')[0]\n",
    "                new_table = new_table.applymap(lambda x: unicodedata.normalize(\n",
    "                    'NFKD', x.strip().strip(u'\\u200b').replace('—', '0').replace('%', '')) if type(x) == str else x)\n",
    "\n",
    "                new_table = new_table.replace(\n",
    "                    r'^\\s*$', np.nan, regex=True).replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "                new_table = new_table.dropna(how='all', axis=0)\n",
    "\n",
    "                if master_table is None:\n",
    "                    master_table = new_table\n",
    "                else:\n",
    "                    master_table = pd.concat(\n",
    "                        [master_table, new_table], ignore_index=True)\n",
    "            # print(master_table)\n",
    "\n",
    "    master_table = master_table.applymap(\n",
    "        lambda x: x.strip().strip(u'\\u200b') if type(x) == str else x)\n",
    "    master_table = master_table.replace(r'^\\s*$', np.nan, regex=True).replace(\n",
    "        r'^\\s*\\$\\s*$', np.nan, regex=True).replace(r'^\\s*\\)\\s*$', np.nan, regex=True)\n",
    "    print(master_table.shape)\n",
    "    data_frames.append(master_table)\n",
    "    data_frames_shapes.append(master_table.shape)\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table_fun(soi_table_df, process_tables_shapes):\n",
    "    print(1, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df = soi_table_df.replace(r'^\\s*\\$\\s*$', np.nan, regex=True)\n",
    "    soi_table_df = soi_table_df.replace(r'\\n', '', regex=True)\n",
    "    print(2, 'shape:', soi_table_df.shape)\n",
    "    print(6, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df = soi_table_df.replace('—', 0)\n",
    "    soi_table_df = soi_table_df.replace('-', 0)\n",
    "    print(7, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    soi_table_df = soi_table_df.applymap(\n",
    "        lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    pattern = r'Total\\s+Investments'\n",
    "    # Use the apply function to check if the pattern is in any column for each row\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    # Find the index of the first row that matches the pattern\n",
    "    # Slice the DataFrame to keep only the rows up to and including the first matching row\n",
    "    if soi_table_df[matching_rows].index[0] < 20:\n",
    "        soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[1]].reset_index(\n",
    "            drop=True)\n",
    "    else:\n",
    "        soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[0]].reset_index(\n",
    "            drop=True)\n",
    "\n",
    "# removest end extra\n",
    "    pattern = r'Net asset value per common share|How We Addressed the Matter in Our Audit'\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "\n",
    "    # Check if the pattern exists in the DataFrame\n",
    "    if matching_rows.any():\n",
    "        # Extract rows from the first occurrence onwards\n",
    "        soi_table_df = soi_table_df.iloc[matching_rows.idxmax(\n",
    "        )+1:].reset_index(drop=True)\n",
    "\n",
    "    # removing all col name\n",
    "    pattern = r'(?:Spread\\s*Above|cost|Percentage|Above)'\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    soi_table_df = soi_table_df[~matching_rows]\n",
    "\n",
    "    print(0, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=1).reset_index(\n",
    "        drop=True)\n",
    "    print(3, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=0).reset_index(\n",
    "        drop=True)\n",
    "    print(4, 'shape:', soi_table_df.shape)\n",
    "    soi_table_df.dropna().reset_index(\n",
    "        drop=True)\n",
    "    print(5, 'shape:', soi_table_df.shape)\n",
    "\n",
    "\n",
    "# drops the sub total\n",
    "    soi_table_df = soi_table_df.dropna(subset=[soi_table_df.columns[0]])\n",
    "\n",
    "    num_cols = soi_table_df.shape[1]\n",
    "    data_col_mapper = dict(zip(soi_table_df.columns.to_list(), [\n",
    "        i for i in range(0, num_cols)]))\n",
    "    soi_table_df = soi_table_df.rename(columns=data_col_mapper)\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if pd.isna(row[column]):\n",
    "                # Find the next column in the same row\n",
    "                next_column = soi_table_df.columns.get_loc(column) + 1\n",
    "                if next_column < len(soi_table_df.columns):\n",
    "                    next_column_name = soi_table_df.columns[next_column]\n",
    "                    # Replace NaN value with the value from the next column\n",
    "                    soi_table_df.at[index, column] = row[next_column_name]\n",
    "                    # Set the next column to NaN\n",
    "                    soi_table_df.at[index, next_column_name] = np.nan\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if pd.isna(row[column]):\n",
    "                while True:\n",
    "                    # Find the next column in the same row\n",
    "                    next_column = soi_table_df.columns.get_loc(column) + 1\n",
    "                    if next_column < len(soi_table_df.columns):\n",
    "                        next_column_name = soi_table_df.columns[next_column]\n",
    "                        # Replace NaN value with the value from the next column\n",
    "                        soi_table_df.at[index, column] = row[next_column_name]\n",
    "                        # Set the next column to NaN\n",
    "                        soi_table_df.at[index, next_column_name] = np.nan\n",
    "                        column = next_column_name\n",
    "                    else:\n",
    "                        # No more columns to replace, break out of the loop\n",
    "                        break\n",
    "\n",
    "    soi_table_df = soi_table_df.dropna(axis=1, thresh=10)\n",
    "    soi_table_df = soi_table_df.dropna(how='all', axis=1).reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    process_tables_shapes.append(soi_table_df.shape)\n",
    "    print(soi_table_df.info())\n",
    "\n",
    "    return soi_table_df\n",
    "\n",
    "\n",
    "process_tables = {}\n",
    "process_tables_shape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1476765/000114420413026113/v343181_10q.htm March 31, 2013\n",
      "March 31, 2013\n",
      "March\n",
      "31, 2013 march312013 march312013\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(html_link, headers\u001b[39m=\u001b[39mheaders)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m content \u001b[39m=\u001b[39m parse_and_trim(response\u001b[39m.\u001b[39mcontent, \u001b[39m'\u001b[39m\u001b[39mHTML\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m master_table \u001b[39m=\u001b[39m extract_tables(content, qtr_date)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m process_table \u001b[39m=\u001b[39m process_table_fun(master_table, process_tables_shape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m process_table\u001b[39m.\u001b[39mto_excel(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     writer, sheet_name\u001b[39m=\u001b[39mqtr_date\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m new_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_html(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     html_table\u001b[39m.\u001b[39mprettify(), keep_default_na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, skiprows\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flavor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbs4\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m new_table \u001b[39m=\u001b[39m new_table\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: unicodedata\u001b[39m.\u001b[39mnormalize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mNFKD\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mstrip(\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\u200b\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m—\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m \u001b[39melse\u001b[39;00m x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m new_table \u001b[39m=\u001b[39m new_table\u001b[39m.\u001b[39;49mreplace(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m^\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms*$\u001b[39;49m\u001b[39m'\u001b[39;49m, np\u001b[39m.\u001b[39;49mnan, regex\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mreplace(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*$\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mnan, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m new_table \u001b[39m=\u001b[39m new_table\u001b[39m.\u001b[39mdropna(how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fuadhassan/Desktop/BDC_RA/GBDC/Code/GBDC.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m master_table \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:5282\u001b[0m, in \u001b[0;36mDataFrame.replace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   5272\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39mreplace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[1;32m   5273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace\u001b[39m(\n\u001b[1;32m   5274\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m     method: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[1;32m   5281\u001b[0m ):\n\u001b[0;32m-> 5282\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreplace(\n\u001b[1;32m   5283\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[1;32m   5284\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m   5285\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5286\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[1;32m   5287\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[1;32m   5288\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   5289\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:6739\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6737\u001b[0m regex \u001b[39m=\u001b[39m should_use_regex(regex, to_replace)\n\u001b[1;32m   6738\u001b[0m \u001b[39mif\u001b[39;00m regex:\n\u001b[0;32m-> 6739\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreplace_regex(\n\u001b[1;32m   6740\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[1;32m   6741\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m   6742\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   6743\u001b[0m     )\n\u001b[1;32m   6744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6745\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m   6746\u001b[0m         to_replace\u001b[39m=\u001b[39mto_replace, value\u001b[39m=\u001b[39mvalue, inplace\u001b[39m=\u001b[39minplace\n\u001b[1;32m   6747\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:446\u001b[0m, in \u001b[0;36mBaseBlockManager.replace_regex\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_regex\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39m_replace_regex\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:761\u001b[0m, in \u001b[0;36mBlock._replace_regex\u001b[0;34m(self, to_replace, value, inplace, convert, mask)\u001b[0m\n\u001b[1;32m    758\u001b[0m rx \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(to_replace)\n\u001b[1;32m    760\u001b[0m new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 761\u001b[0m replace_regex(new_values, rx, value, mask)\n\u001b[1;32m    763\u001b[0m block \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n\u001b[1;32m    764\u001b[0m \u001b[39mreturn\u001b[39;00m block\u001b[39m.\u001b[39mconvert(numeric\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/array_algos/replace.py:153\u001b[0m, in \u001b[0;36mreplace_regex\u001b[0;34m(values, rx, value, mask)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m             \u001b[39mreturn\u001b[39;00m s\n\u001b[0;32m--> 153\u001b[0m f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvectorize(re_replacer, otypes\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mobject_])\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     values[:] \u001b[39m=\u001b[39m f(values)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:2261\u001b[0m, in \u001b[0;36mvectorize.__init__\u001b[0;34m(self, pyfunc, otypes, doc, excluded, cache, signature)\u001b[0m\n\u001b[1;32m   2259\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid otype specified: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (char,))\n\u001b[1;32m   2260\u001b[0m \u001b[39melif\u001b[39;00m iterable(otypes):\n\u001b[0;32m-> 2261\u001b[0m     otypes \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([_nx\u001b[39m.\u001b[39mdtype(x)\u001b[39m.\u001b[39mchar \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m otypes])\n\u001b[1;32m   2262\u001b[0m \u001b[39melif\u001b[39;00m otypes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2263\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid otype specification\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:2261\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2259\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid otype specified: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (char,))\n\u001b[1;32m   2260\u001b[0m \u001b[39melif\u001b[39;00m iterable(otypes):\n\u001b[0;32m-> 2261\u001b[0m     otypes \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([_nx\u001b[39m.\u001b[39;49mdtype(x)\u001b[39m.\u001b[39mchar \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m otypes])\n\u001b[1;32m   2262\u001b[0m \u001b[39melif\u001b[39;00m otypes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2263\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid otype specification\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# This does the job\n",
    "path = '/Users/fuadhassan/Desktop/BDC_RA/GBDC/Tr_GBDC_Investment.xlsx'\n",
    "writer = pd.ExcelWriter(path, engine='openpyxl')\n",
    "for qtr_date, html_link in zip(filing_links['Reporting date'], filing_links['Filings URL']):\n",
    "    print(html_link, qtr_date)\n",
    "    response = requests.get(html_link, headers=headers)\n",
    "    content = parse_and_trim(response.content, 'HTML')\n",
    "    master_table = extract_tables(content, qtr_date)\n",
    "    process_table = process_table_fun(master_table, process_tables_shape)\n",
    "    process_table.to_excel(\n",
    "        writer, sheet_name=qtr_date.replace(',', ''), index=False)\n",
    "    writer.book .save(path)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "# last work Nov 6th 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(370, 10),\n",
       " (370, 14),\n",
       " (386, 10),\n",
       " (382, 14),\n",
       " (403, 12),\n",
       " (416, 12),\n",
       " (436, 10),\n",
       " (434, 13),\n",
       " (449, 10),\n",
       " (477, 10),\n",
       " (487, 10),\n",
       " (430, 14),\n",
       " (515, 11),\n",
       " (479, 9),\n",
       " (13, 2),\n",
       " (587, 13),\n",
       " (614, 13),\n",
       " (640, 13),\n",
       " (671, 14),\n",
       " (707, 14),\n",
       " (745, 14),\n",
       " (786, 13),\n",
       " (849, 13),\n",
       " (883, 13),\n",
       " (925, 13),\n",
       " (1021, 15),\n",
       " (1073, 13),\n",
       " (1116, 13),\n",
       " (1115, 13),\n",
       " (1147, 13),\n",
       " (1185, 13),\n",
       " (1237, 13),\n",
       " (1318, 13),\n",
       " (1429, 13),\n",
       " (1443, 13),\n",
       " (1541, 13),\n",
       " (1634, 13),\n",
       " (1627, 16),\n",
       " (1630, 16),\n",
       " (1470, 16),\n",
       " (1392, 16)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tables_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
