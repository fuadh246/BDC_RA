{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "import webbrowser\n",
    "import html5lib\n",
    "from openpyxl import workbook\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Master_tables_GBDC_Investment.xlsx'\n",
    "dataframes = pd.read_excel(path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tables = {}\n",
    "process_tables_shape = {}\n",
    "if not os.path.exists('../Test_PT_csv_file'):\n",
    "    os.makedirs('../Test_PT_csv_file')\n",
    "\n",
    "\n",
    "def run_process_function(dataframes, process_tables, process_tables_shape):\n",
    "    path = '../test_process_tables_GBDC_Investment.xlsx'\n",
    "    writer = pd.ExcelWriter(path=path, engine='openpyxl')\n",
    "    for dataframe in dataframes:\n",
    "        print(dataframe)\n",
    "        processed_table = process_table_function(dataframes[dataframe])\n",
    "        process_tables[dataframe] = processed_table\n",
    "        process_tables_shape[dataframe] = processed_table.shape\n",
    "        processed_table.to_excel(\n",
    "            writer, sheet_name=dataframe.replace(',', ''), index=False)\n",
    "        processed_table.to_csv(\n",
    "            '../PT_csv_file/'+dataframe.replace(',', '')+'.csv')\n",
    "        writer.book.save(path)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(count, df):\n",
    "    print(f\"{count} : shape : {df.shape}\")\n",
    "    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def dropna_col_row(df):\n",
    "    df = df.dropna(how='all', axis=0).reset_index(drop=True)\n",
    "    df = df.dropna(how='all', axis=1).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_if_contain(pattern, df):\n",
    "    matching_rows = df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    df = df[~matching_rows]\n",
    "    return df\n",
    "\n",
    "\n",
    "def rename_columns(df):\n",
    "    num_cols = df.shape[1]\n",
    "    data_col_mapper = dict(\n",
    "        zip(df.columns.to_list(), [i for i in range(0, num_cols)]))\n",
    "    df = df.rename(columns=data_col_mapper)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table_function(soi_table_df):\n",
    "    count = 1\n",
    "    count = shape(count, soi_table_df)\n",
    "    soi_table_df = soi_table_df.replace(\n",
    "        r'^\\s*\\$\\s*$', '', regex=True).replace(r'\\n', '', regex=True)\n",
    "    soi_table_df = soi_table_df.replace('-', '0')\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    soi_table_df = soi_table_df.apply(\n",
    "        lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    # drops all the extra top row\n",
    "    pattern = r'Net asset value per common share|How We Addressed the Matter in Our Audit'\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    # Check if the pattern exists in the DataFrame\n",
    "    if matching_rows.any():\n",
    "        # Extract rows from the first occurrence onwards\n",
    "        soi_table_df = soi_table_df.iloc[matching_rows.idxmax(\n",
    "        )+1:].reset_index(drop=True)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    # drops all the extra bottom row\n",
    "    pattern = r'Total\\s+Investments'\n",
    "    # Use the apply function to check if the pattern is in any column for each row\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    # Find the index of the first row that matches the pattern\n",
    "    # Slice the DataFrame to keep only the rows up to and including the first matching row\n",
    "    if soi_table_df[matching_rows].index[0] < 20:\n",
    "        soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[1]].reset_index(\n",
    "            drop=True)\n",
    "    else:\n",
    "        soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[0]].reset_index(\n",
    "            drop=True)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    # drop all the col name\n",
    "    pattern = r'(?:Spread\\s*Above|cost|Percentage|Above)'\n",
    "    soi_table_df = drop_if_contain(pattern, soi_table_df)\n",
    "    pattern = r'^([Tt]otal)'\n",
    "    soi_table_df = drop_if_contain(pattern, soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "# drop nan col row\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "# drops the sub total\n",
    "    soi_table_df = soi_table_df.dropna(subset=[soi_table_df.columns[0]])\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "\n",
    "# rename col\n",
    "    soi_table_df = rename_columns(soi_table_df)\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            # pattern = re.compile(r'\\([a-zA-Z]\\)')\n",
    "            pattern = re.compile(r'\\(\\s*[a-zA-Z]\\s*\\)')\n",
    "            if str(row[column])[-1] == \"+\" or '+' in str(row[column]):\n",
    "                next_column_index = soi_table_df.columns.get_loc(\n",
    "                    column) + 1\n",
    "                if str(row[column])[-1] == \"+\":\n",
    "                    if (next_column_index < len(soi_table_df.columns)\n",
    "                                and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                            ):\n",
    "                        soi_table_df.at[index, column] = str(\n",
    "                            soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])\n",
    "                        soi_table_df.at[index,\n",
    "                                        soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "                    next_column_index = soi_table_df.columns.get_loc(\n",
    "                        next_column_index) + 1\n",
    "                if (\n",
    "                    next_column_index < len(soi_table_df.columns)\n",
    "                    and pattern.search(str(row[soi_table_df.columns[next_column_index]]))\n",
    "                    and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                ):\n",
    "                    soi_table_df.at[index, column] = str(\n",
    "                        soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])\n",
    "                    soi_table_df.at[index,\n",
    "                                    soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "            if row[column] == \"No Value\":\n",
    "                pattern = re.compile(r'\\([0-9]\\)')\n",
    "                next_column_index = soi_table_df.columns.get_loc(column) + 1\n",
    "                if (\n",
    "                    next_column_index < len(soi_table_df.columns)\n",
    "                    and pattern.search(str(row[soi_table_df.columns[next_column_index]]))\n",
    "                    and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                ):\n",
    "                    soi_table_df.at[index,\n",
    "                                    column] = row[soi_table_df.columns[next_column_index]]\n",
    "                    soi_table_df.at[index,\n",
    "                                    soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "    soi_table_df.insert(0, 'Industy', '')\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        if row.nunique() == 2:\n",
    "            soi_table_df.at[index, 'Industy'] = row.loc[0]\n",
    "    soi_table_df['Industy'] = soi_table_df['Industy'].replace('', np.nan)\n",
    "\n",
    "    col_indices = [0, 1, 2]\n",
    "    soi_table_df.iloc[:, col_indices] = soi_table_df.iloc[:, col_indices].fillna(\n",
    "        method='ffill')\n",
    "    col_indices = [0]\n",
    "    soi_table_df.iloc[:, col_indices] = soi_table_df.iloc[:,\n",
    "                                                          col_indices].fillna('No value')\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        cleanedList = [x for x in list(row) if str(x) != 'nan']\n",
    "        row = pd.Series(cleanedList)\n",
    "        soi_table_df.loc[index] = row\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if row[column] == \"cash/\":\n",
    "                prev_column_index = soi_table_df.columns.get_loc(column) - 1\n",
    "                next_column_index = soi_table_df.columns.get_loc(column) + 1\n",
    "                soi_table_df.at[index, soi_table_df.columns[prev_column_index]] = str(row[soi_table_df.columns[prev_column_index]]) + str(\n",
    "                    soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])+str(row[soi_table_df.columns[next_column_index+1]])\n",
    "                soi_table_df.at[index,\n",
    "                                soi_table_df.columns[next_column_index]] = np.nan\n",
    "                soi_table_df.at[index,\n",
    "                                soi_table_df.columns[next_column_index+1]] = np.nan\n",
    "                soi_table_df.at[index, column] = np.nan\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if row[column] == \"PIK\" or row[column] == 'Non-Cash':\n",
    "                prev_column_index = soi_table_df.columns.get_loc(column) - 1\n",
    "                soi_table_df.at[index, soi_table_df.columns[prev_column_index]] = str(soi_table_df.at[index, soi_table_df.columns[prev_column_index]]) + str(\n",
    "                    soi_table_df.at[index, column])\n",
    "\n",
    "                soi_table_df.at[index, column] = np.nan\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        cleanedList = [x for x in list(row) if str(x) != 'nan']\n",
    "        row = pd.Series(cleanedList)\n",
    "        soi_table_df.loc[index] = row\n",
    "\n",
    "\n",
    "# drop nan col row\n",
    "    # soi_table_df = soi_table_df.dropna(axis=0, thresh=4)\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "# rename col\n",
    "    soi_table_df = rename_columns(soi_table_df)\n",
    "\n",
    "    new_column_names = ['Industry', 'Company', 'Investment Type', 'Spread Above Index',\n",
    "                        'Interest Rate', 'Maturity Date', 'Principal Shares', 'Amortized Cost',\n",
    "                        'Percentage of Net Assets', 'Fair Value']\n",
    "\n",
    "# Set the first 10 column headers\n",
    "    soi_table_df.columns = new_column_names + list(soi_table_df.columns[10:])\n",
    "\n",
    "    return soi_table_df\n",
    "\n",
    "\n",
    "run_process_function(dataframes=dataframes, process_tables=process_tables,\n",
    "                     process_tables_shape=process_tables_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'March 31 2013': (365, 10),\n",
       " 'June 30 2013': (365, 10),\n",
       " 'September 30 2013': (381, 10),\n",
       " 'December 31 2013': (378, 10),\n",
       " 'March 31 2014': (399, 10),\n",
       " 'June 30 2014': (412, 10),\n",
       " 'September 30 2014': (432, 10),\n",
       " 'December 31 2014': (430, 10),\n",
       " 'March 31 2015': (445, 10),\n",
       " 'June 30 2015': (473, 10),\n",
       " 'September 30 2015': (483, 10),\n",
       " 'December 31 2015': (425, 10),\n",
       " 'March 31 2016': (505, 10),\n",
       " 'June 30 2016': (469, 10),\n",
       " 'September 30 2016': (582, 10),\n",
       " 'December 31 2016': (579, 10),\n",
       " 'March 31 2017': (606, 10),\n",
       " 'June 30 2017': (635, 10),\n",
       " 'December 31 2017': (663, 10),\n",
       " 'March 31 2018': (699, 10),\n",
       " 'June 30 2018': (737, 10),\n",
       " 'September 30 2018': (778, 10),\n",
       " 'December 31 2018': (841, 10),\n",
       " 'March 31 2019': (875, 10),\n",
       " 'June 30 2019': (917, 10),\n",
       " 'September 30 2019': (1013, 10),\n",
       " 'December 31 2019': (1063, 10),\n",
       " 'March 31 2020': (1106, 11),\n",
       " 'June 30 2020': (1105, 10),\n",
       " 'September 30 2020': (1138, 10),\n",
       " 'December 31 2020': (1175, 10),\n",
       " 'March 31 2021': (1227, 10),\n",
       " 'June 30 2021': (1308, 10),\n",
       " 'September 30 2021': (1419, 10),\n",
       " 'December 31 2021': (1433, 10),\n",
       " 'March 31 2022': (1531, 10),\n",
       " 'June 30 2022': (1624, 10),\n",
       " 'September 30 2022': (1617, 10),\n",
       " 'December 31 2022': (1620, 11),\n",
       " 'March 31 2023': (1460, 10),\n",
       " 'June 30 2023': (1383, 10)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tables_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
