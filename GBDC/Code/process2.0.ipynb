{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "import webbrowser\n",
    "import html5lib\n",
    "from openpyxl import workbook\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../section_tables_GBDC_Investment.xlsx'\n",
    "dataframes = pd.read_excel(path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tables = {}\n",
    "process_tables_shape = {}\n",
    "if not os.path.exists('../PT_csv_file'):\n",
    "    os.makedirs('../PT_csv_file')\n",
    "\n",
    "\n",
    "def run_process_function(dataframes, process_tables, process_tables_shape):\n",
    "    path = '../feedback_process_tables_GBDC_Investment.xlsx'\n",
    "    writer = pd.ExcelWriter(path=path, engine='openpyxl')\n",
    "    for dataframe in dataframes:\n",
    "        print(dataframe)\n",
    "        processed_table = process_table_function(dataframes[dataframe])\n",
    "        process_tables[dataframe] = processed_table\n",
    "        process_tables_shape[dataframe] = processed_table.shape\n",
    "        processed_table.to_excel(\n",
    "            writer, sheet_name=dataframe.replace(',', ''), index=False)\n",
    "        processed_table.to_csv(\n",
    "            '../PT_csv_file/'+dataframe.replace(',', '')+'.csv')\n",
    "        writer.book.save(path)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(count, df):\n",
    "    print(f\"{count} : shape : {df.shape}\")\n",
    "    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def dropna_col_row(df):\n",
    "    df = df.dropna(how='all', axis=0).reset_index(drop=True)\n",
    "    df = df.dropna(how='all', axis=1).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_if_contain(pattern, df):\n",
    "    matching_rows = df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    df = df[~matching_rows]\n",
    "    return df\n",
    "\n",
    "\n",
    "def rename_columns(df):\n",
    "    num_cols = df.shape[1]\n",
    "    data_col_mapper = dict(\n",
    "        zip(df.columns.to_list(), [i for i in range(0, num_cols)]))\n",
    "    df = df.rename(columns=data_col_mapper)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table_function(soi_table_df):\n",
    "    count = 1\n",
    "    count = shape(count, soi_table_df)\n",
    "    soi_table_df = soi_table_df.replace(\n",
    "        r'^\\s*\\$\\s*$', '', regex=True).replace(r'\\n', '', regex=True)\n",
    "\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    soi_table_df = soi_table_df.apply(\n",
    "        lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    # drops all the extra top row\n",
    "    pattern = r'(?:Spread\\s*Above|Percentage|Above)'\n",
    "    matching_rows = soi_table_df.apply(lambda row: row.str.contains(\n",
    "        pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    # Check if the pattern exists in the DataFrame\n",
    "    if matching_rows.any():\n",
    "        # Extract rows from the first occurrence onwards\n",
    "        soi_table_df = soi_table_df.iloc[matching_rows.idxmax(\n",
    "        )+1:].reset_index(drop=True)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    (matching_rows).to_csv('test.csv')\n",
    "\n",
    "    # drops all the extra bottom row\n",
    "    pattern = r'Total\\s+Investments'\n",
    "    # Use the apply function to check if the pattern is in any column for each row\n",
    "    matching_rows = soi_table_df.apply(\n",
    "        lambda row: row.str.contains(pattern, flags=re.IGNORECASE, regex=True).any(), axis=1)\n",
    "    # Find the index of the first row that matches the pattern\n",
    "    # Slice the DataFrame to keep only the rows up to and including the first matching row\n",
    "    # if soi_table_df[matching_rows].index[0] < 20:\n",
    "    #     soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[1]].reset_index(\n",
    "    #         drop=True)\n",
    "    # else:\n",
    "    soi_table_df = soi_table_df.loc[:soi_table_df[matching_rows].index[0]].reset_index(\n",
    "        drop=True)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "    # drop all the col name\n",
    "    pattern = r'Spread\\s*Above|cost|Percentage|Above'\n",
    "    soi_table_df = drop_if_contain(pattern, soi_table_df)\n",
    "    pattern = r'^([Tt]otal)'\n",
    "    soi_table_df = drop_if_contain(pattern, soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "# drop nan col row\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "# drops the sub total\n",
    "    soi_table_df = soi_table_df.dropna(subset=[soi_table_df.columns[0]])\n",
    "    count = shape(count, soi_table_df)\n",
    "\n",
    "\n",
    "# rename col\n",
    "    soi_table_df = rename_columns(soi_table_df)\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            pattern = re.compile(r'\\(\\s*[a-zA-Z]\\s*\\)')\n",
    "            if str(row[column])[-1] == \"+\" or '+' in str(row[column]):\n",
    "                next_column_index = soi_table_df.columns.get_loc(\n",
    "                    column) + 1\n",
    "                if str(row[column])[-1] == \"+\":\n",
    "                    if (next_column_index < len(soi_table_df.columns)\n",
    "                            and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                        ):\n",
    "                        soi_table_df.at[index, column] = str(\n",
    "                            soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])\n",
    "                        soi_table_df.at[index,\n",
    "                                        soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "                    next_column_index = soi_table_df.columns.get_loc(\n",
    "                        next_column_index) + 1\n",
    "                if (\n",
    "                    next_column_index < len(soi_table_df.columns)\n",
    "                    and pattern.search(str(row[soi_table_df.columns[next_column_index]]))\n",
    "                    and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                ):\n",
    "                    soi_table_df.at[index, column] = str(\n",
    "                        soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])\n",
    "                    soi_table_df.at[index,\n",
    "                                    soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "            if row[column] == \"No Value\":\n",
    "                pattern = re.compile(r'\\([0-9]\\)')\n",
    "                next_column_index = soi_table_df.columns.get_loc(column) + 1\n",
    "                if (\n",
    "                    next_column_index < len(soi_table_df.columns)\n",
    "                    and pattern.search(str(row[soi_table_df.columns[next_column_index]]))\n",
    "                    and not pd.isna(row[soi_table_df.columns[next_column_index]])\n",
    "                ):\n",
    "                    soi_table_df.at[index,\n",
    "                                    column] = row[soi_table_df.columns[next_column_index]]\n",
    "                    soi_table_df.at[index,\n",
    "                                    soi_table_df.columns[next_column_index]] = np.nan\n",
    "\n",
    "    soi_table_df.insert(0, 'Industy', '')\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        if row.nunique() == 2:\n",
    "            soi_table_df.at[index, 'Industy'] = row.loc[0]\n",
    "    soi_table_df['Industy'] = soi_table_df['Industy'].replace('', np.nan)\n",
    "\n",
    "    col_indices = [0, 1, 2]\n",
    "    soi_table_df.iloc[:, col_indices] = soi_table_df.iloc[:, col_indices].fillna(\n",
    "        method='ffill')\n",
    "    col_indices = [0]\n",
    "    soi_table_df.iloc[:, col_indices] = soi_table_df.iloc[:,\n",
    "                                                          col_indices].fillna('No value')\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        cleanedList = [x for x in list(row) if str(x) != 'nan']\n",
    "        row = pd.Series(cleanedList)\n",
    "        soi_table_df.loc[index] = row\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if row[column] == \"cash/\":\n",
    "                prev_column_index = soi_table_df.columns.get_loc(column) - 1\n",
    "                next_column_index = soi_table_df.columns.get_loc(column) + 1\n",
    "                soi_table_df.at[index, soi_table_df.columns[prev_column_index]] = str(row[soi_table_df.columns[prev_column_index]]) + str(\n",
    "                    soi_table_df.at[index, column])+str(row[soi_table_df.columns[next_column_index]])+str(row[soi_table_df.columns[next_column_index+1]])\n",
    "                soi_table_df.at[index,\n",
    "                                soi_table_df.columns[next_column_index]] = np.nan\n",
    "                soi_table_df.at[index,\n",
    "                                soi_table_df.columns[next_column_index+1]] = np.nan\n",
    "                soi_table_df.at[index, column] = np.nan\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        for column in soi_table_df.columns:\n",
    "            if row[column] == \"PIK\" or row[column] == 'Non-Cash':\n",
    "                prev_column_index = soi_table_df.columns.get_loc(column) - 1\n",
    "                soi_table_df.at[index, soi_table_df.columns[prev_column_index]] = str(soi_table_df.at[index, soi_table_df.columns[prev_column_index]]) + str(\n",
    "                    soi_table_df.at[index, column])\n",
    "\n",
    "                soi_table_df.at[index, column] = np.nan\n",
    "\n",
    "    for index, row in soi_table_df.iterrows():\n",
    "        cleanedList = [x for x in list(row) if str(x) != 'nan']\n",
    "        row = pd.Series(cleanedList)\n",
    "        soi_table_df.loc[index] = row\n",
    "\n",
    "\n",
    "# drop nan col row\n",
    "    # soi_table_df = soi_table_df.dropna(axis=0, thresh=4)\n",
    "    soi_table_df = dropna_col_row(soi_table_df)\n",
    "    count = shape(count, soi_table_df)\n",
    "# rename col\n",
    "    soi_table_df = rename_columns(soi_table_df)\n",
    "\n",
    "    new_column_names = ['Industry', 'Company', 'Investment Type', 'Spread Above Index',\n",
    "                        'Interest Rate', 'Maturity Date', 'Principal Shares', 'Amortized Cost',\n",
    "                        'Percentage of Net Assets', 'Fair Value']\n",
    "\n",
    "# Set the first 10 column headers\n",
    "    soi_table_df.columns = new_column_names + list(soi_table_df.columns[10:])\n",
    "\n",
    "    # soi_table_df['Principal Shares'] = pd.to_numeric(\n",
    "    #     soi_table_df['Principal Shares'], errors='coerce')\n",
    "    # soi_table_df['Amortized Cost'] = pd.to_numeric(\n",
    "    #     soi_table_df['Amortized Cost'], errors='coerce')\n",
    "    # soi_table_df['Percentage of Net Assets'] = pd.to_numeric(\n",
    "    #     soi_table_df['Percentage of Net Assets'], errors='coerce')\n",
    "    # soi_table_df['Fair Value'] = pd.to_numeric(\n",
    "    #     soi_table_df['Fair Value'], errors='coerce')\n",
    "\n",
    "    return soi_table_df\n",
    "\n",
    "\n",
    "run_process_function(dataframes=dataframes, process_tables=process_tables,\n",
    "                     process_tables_shape=process_tables_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "columns_to_process = ['Amortized Cost', 'Fair Value']\n",
    "table = \"\"\n",
    "# Iterate over each column\n",
    "# Iterate over each table\n",
    "for table_name, table_df in process_tables.items():\n",
    "    print('\\n', table_name)\n",
    "\n",
    "    # Iterate over each column\n",
    "    for column in columns_to_process:\n",
    "        # Convert \"-\" and None values to NaN and replace certain patterns\n",
    "        col = table_df[column].replace(\n",
    "            [\"-\", None, r'\\s*\\(\\s*\\d+\\s*\\)\\s*', r'\\(\\d'], None, regex=True)\n",
    "\n",
    "        # Convert the column to float\n",
    "        col = col.astype(float)\n",
    "\n",
    "        # Calculate the sum\n",
    "        column_sum = col.sum()\n",
    "\n",
    "        print(\"Sum of\", column, \"column:\", column_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "June_30_2023 = (5605521, 5525009)\n",
    "March_31_2023 = (5618695, 5486352)\n",
    "December_31_2022 = (535583415, 5451946)\n",
    "September_30_2022 = (5569604, 5446356)  # Real Estate Management & Development\n",
    "June_30_2022 = (5656202, 5613550)  # Real Estate Management & Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = process_tables['September 30 2022']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_process:\n",
    "    # Convert \"-\" and None values to NaN and replace certain patterns\n",
    "    col = table_df[column].replace(\n",
    "        [\"-\", None, r'\\s*\\(\\s*\\d+\\s*\\)\\s*', r'\\(\\d'], None, regex=True)\n",
    "\n",
    "    # Convert the column to float\n",
    "    col = col.astype(float)\n",
    "\n",
    "    # Calculate the sum\n",
    "    column_sum = col.sum()\n",
    "    print(\"Sum of\", column, \"column:\", column_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../new_FBMT_csv_file/December 31 2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabel = process_table_function(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabel.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
